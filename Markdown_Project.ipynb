{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kori04/CSC445Final/blob/main/Markdown_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dNq2eCCxAYu"
      },
      "source": [
        "# Evolution of cooperation\n",
        "\n",
        "Code examples from [Think Complexity, 2nd edition](https://thinkcomplex.com).\n",
        "\n",
        "Copyright 2016 Allen Downey, [MIT License](http://opensource.org/licenses/MIT)\n",
        "\n",
        "Code Enhancements and Write Up : Andrea Ola, Kori Kobylak"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "The Prisoner's Dilemma is a game theory problem which analyzes what people will do when presented with the choice to perform an act in secret which can get them larger payoffs if the other player(s) don't do the same thing. In the version the game gets its name from, two prisoners are presented a choice, they can either snitch or not snitch. If both choose to not snitch they will each get an equally long sentence of four years. If one chooses to snitch and the other doesn't the one who snitches will get one year and the one who didn't will get 6 years. However, if they both choose to snitch they will each get 5 years. So, what is the optimal choice? That is what this will explore looking at both long term and short terms games of the prisoner's dilemma.\n",
        "\n",
        "The way we simulate this is by utilizing a tournament style to determine which Prisoner's Dilemma strategies come out on top after playing for a length of chosen time. We do this by killing off the weakest strategies and slightly changing strategies that did well to figure out the best over time.  We analyze this overtime evolution using 5 data sets. (Kuhn, 2019)\n",
        "\n",
        "\n",
        "*   Mean Fitness - This is the average score of all agents over time\n",
        "*   Niceness - Average number of Cs in agents across all agents\n",
        "*   Opening - Average number of agents who started by cooperating\n",
        "*   Retaliation - Difference between number of agents who when snitched on, retaliate on the next step and who cooperate\n",
        "*   Forgiving - Average number of agents who forgive defection while the defection is still in memory\n",
        "\n",
        "These five data points allow us to closely view what changes in agents over time and what types of strategies will come out on top. In early tournaments different agents were submitted and pitted against each other to see what would come out on top. We have recreated a similar experiment below but for now you just need to know in the original experiment Tit for Tat (TfT) came out on top. (Tobin)\n",
        "\n",
        "Agents are composed of 7 Cs and or Ds with each one telling it what to do based on the oponent's last two actions. Let us break this down by looking at TfT and what its Cooperate (Cs) and Defect (Ds) can tell us about it.\n",
        "\n",
        "The Seven letter string for TfT is as follows, 'CCDCDCD'\n",
        "- The First C means it will always start by cooperating\n",
        "- The Second C means that if the opponent chooses to Cooperate then TfT will cooperate again on the second move\n",
        "- The First D means that, if the opponent chooses to defect in the first move then TfT will defect on the second move\n",
        "\n",
        "From here the rest of these letters will apply to the last two moves the opponent made starting with,\n",
        "- The Third C means that if the opponent cooperated for the past two moves than TfT will as well\n",
        "- The Second D means that if the opponent cooperated and then defected then TfT will defect on the next move\n",
        "- The Final C meants that if the opponent defected and then cooperated then TfT will cooperate again\n",
        "- And the final D means that if the opponent defected twice recently then TfT will defect.\n",
        "\n",
        "This makes Tit for Tat a strategy that is nice meaning it cooperates first, but it is also relaitory as it will retaliate if something defects. But it also is forgiving, meaning that if the opponent after defecting goes back cooperating then TfT will as well. And finally it is clear, making it easy to use for mutual improvement. (Kuhn, 2019)"
      ],
      "metadata": {
        "id": "VwI2HsiGIn4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Code Enhancements\n",
        "###Enhancing the Code with a Round-Robin Tournament Method\n",
        "In simulations such as the Prisoner’s Dilemma, evaluating the interactions between agents is crucial to understand the dynamics of different strategies. The original code employs a Melee Tournament, where each agent interacts with two neighbors (where the interactions can be chosen randomly, depending on whether the randomize parameter is set to True). While this approach is computationally efficient, it introduces randomness in pairings and provides only a limited view of how strategies perform across a population. By adding a Round-Robin Tournament method, we can significantly enhance the analysis, ensuring that each agent interacts with every other agent in the population. This allows for a more comprehensive and unbiased evaluation of strategy performance (Kretz, 2010).\n",
        "\n",
        "The Round-Robin Tournament addresses the limitations of the Melee Tournament by eliminating pairing bias and providing a complete view of strategy performance. In the Melee Tournament, fitness is based on interactions with only two opponents per step, which limits the evaluation of an agent’s effectiveness across the population. In contrast, the Round-Robin Tournament ensures that every agent competes against all others, providing fitness values that reflect a strategy’s overall performance. These fitness values are calculated from the total score of all matches and normalized by the number of matches per agent and the number of rounds per match, enabling fair and consistent comparisons. This approach makes the Round-Robin method especially effective for analyzing diverse strategies.\n",
        "\n",
        "**How the Round-Robin Method Works**\n",
        "The round_robin method ensures every agent interacts with all others in the population:\n",
        "A nested loop iterates over all pairs of agents.\n",
        "1. A nested loop iterates over all pairs of agents.\n",
        "2. Each pair plays a multi-round match using the play method.\n",
        "3. Scores from all matches are accumulated for each agent.\n",
        "4. Fitness values are computed as the average score per match, normalized by the number of matches and rounds played.\n",
        "For example, in a population of three agents:\n",
        "  Agent 0 plays against Agent 1, Agent 2, and itself.\n",
        "  Agent 1 plays against Agent 0, Agent 2, and itself.\n",
        "  Agent 2 plays against Agent 0, Agent 1, and itself.\n",
        "  For this scenario, at the end of the tournament, all agents will have played two matches, and their fitness values will reflect their average performance across those matches.\n",
        "**New Special Agents**\n",
        "In addition adding a new interaction method, we expanded the set of strategies available for agents by adding three new strategies to complement the already-implemented Always Cooperate, Always Defect, and Tit-for-Tat. The new strategies include:\n",
        "* No Forgiveness (nf): Represented as Agent('CCDCDDD'), this strategy starts with cooperation but gradually shifts to defection with no intention to return to cooperation.\n",
        "* Backstabbing (back): Represented as Agent('CDCDCDC'), this strategy alternates between cooperation and defection, mimicking unstable or deceptive behavior.\n",
        "* Start with Defection (StartDef): Represented as Agent('DCCCCCC'), this strategy begins with defection but shifts to cooperation in subsequent interactions.\n",
        "These new strategies provide a richer simulation by introducing behaviors that mimic real-world complexities, such as gradual betrayal, alternating trust, and a willingness to change tactics. By analyzing interactions among this expanded pool of strategies, we can gain deeper insights into the dynamics of cooperation, defection, and trust-building.\n",
        "##Demonstration\n",
        "For our demonstration, we ran a simulation focused entirely on the Backstabbing Agent, using a population of 100 agents over 2,500 steps. This allowed us to observe how this strategy evolved and interacted within its group.\n",
        "Graphs tracking metrics such as mean fitness, niceness, retaliation, and forgiveness highlighted dynamic fluctuations in strategy effectiveness over time. The results revealed that, while initially biased toward defecting behaviors, the population gradually stabilized with agents adopting a mix of cooperative and strategic defecting optimize fitness.\n",
        "\n",
        "**Interactive Simulation Setup**\n",
        "\n",
        "Finally, we made the simulation setup more user-friendly by allowing users to input custom configurations, including the agent genome, population size, and the number of simulation steps. This interactive setup makes the simulation more accessible for testing various scenarios and observing diverse outcomes.\n",
        "\n",
        "*For more detailed results you can view the Designed Simulation section.*\n",
        "##Critique\n",
        "Future Enhancements: Implementing Memory-Size-Three Strategies\n",
        "While we think that implmenting a new type of tournamnet and new special gents added some new interesting features to study, we believe that in the future expanding to memory-size-three strategies offers an exciting opportunity to analyze more complex decision-making processes. These strategies consider the outcomes of the last three rounds of interactions, enabling agents to make decisions based on more information collected from previous rounds (Kretz, 2010).\n",
        "To implement this enhancement, we would need to:\n",
        "* Extend the agent's memory to store three rounds of interaction history.\n",
        "* Adjust the agent's strategy dictionary to include 64 keys, representing all possible combinations of outcomes for three rounds.\n",
        "* Update the respond method to use these keys for determining actions.\n",
        "While this change increases computational complexity due to the larger strategy space, it significantly enriches the analysis by introducing more intricate decision-making possibilities. This could reveal new dynamics in how strategies compete and adapt over time, offering insights into behaviors that cannot emerge with simpler memory strategies."
      ],
      "metadata": {
        "id": "KXkzq39lOrnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Writeup Segement\n",
        "\n",
        "Below is all code, complexity analysis, and an analysis of specific simulation\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ln6JMe3_Ink3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR_tufC3xAYw"
      },
      "source": [
        "### Previous code (Untouched)\n",
        "\n",
        "From the Chapter 11 notebook, we will reuse `Simulation` and `Instrument`.\n",
        "\n",
        "Since code in this section is mostly set-up code any code in here is set-up and stays either O(n) or O(1), this is because no other operations apart from variable set-up, simple calculations, or use of single for loops are done.\n",
        "\n",
        "*See comment below each method to for found complexity.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oKgn6erixAYw"
      },
      "outputs": [],
      "source": [
        "class Simulation:\n",
        "\n",
        "    def __init__(self, fit_land, agents):\n",
        "        \"\"\"Create the simulation:\n",
        "\n",
        "        fit_land: fit_land\n",
        "        num_agents: int number of agents\n",
        "        agent_maker: function that makes agents\n",
        "        \"\"\"\n",
        "        self.fit_land = fit_land\n",
        "        self.agents = np.asarray(agents)\n",
        "        self.instruments = []\n",
        "        #Complexity O(1)\n",
        "\n",
        "    def add_instrument(self, instrument):\n",
        "        \"\"\"Adds an instrument to the list.\n",
        "\n",
        "        instrument: Instrument object\n",
        "        \"\"\"\n",
        "        self.instruments.append(instrument)\n",
        "         #Complexity O(1)\n",
        "\n",
        "    def plot(self, index, *args, **kwargs):\n",
        "        \"\"\"Plot the results from the indicated instrument.\n",
        "        \"\"\"\n",
        "        self.instruments[index].plot(*args, **kwargs)\n",
        "         #Complexity O(1)\n",
        "\n",
        "    def run(self, num_steps=500):\n",
        "        \"\"\"Run the given number of steps.\n",
        "\n",
        "        num_steps: integer\n",
        "        \"\"\"\n",
        "        # initialize any instruments before starting\n",
        "        self.update_instruments()\n",
        "\n",
        "        for _ in range(num_steps):\n",
        "            self.step()\n",
        "         #Complexity O(n) where n is number of steps\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\"Simulate a time step and update the instruments.\n",
        "        \"\"\"\n",
        "        n = len(self.agents)\n",
        "        fits = self.get_fitnesses()\n",
        "\n",
        "        # see who dies\n",
        "        index_dead = self.choose_dead(fits)\n",
        "        num_dead = len(index_dead)\n",
        "\n",
        "        # replace the dead with copies of the living\n",
        "        replacements = self.choose_replacements(num_dead, fits)\n",
        "        self.agents[index_dead] = replacements\n",
        "\n",
        "        # update any instruments\n",
        "        self.update_instruments()\n",
        "\n",
        "        #Complexity O(1)\n",
        "\n",
        "    def update_instruments(self):\n",
        "        for instrument in self.instruments:\n",
        "            instrument.update(self)\n",
        "         #Complexity O(n) where n is the number of instruments we are working with\n",
        "\n",
        "    def get_locs(self):\n",
        "        \"\"\"Returns a list of agent locations.\"\"\"\n",
        "        return [tuple(agent.loc) for agent in self.agents]\n",
        "        #Complexity O(n) where n is number of agents\n",
        "\n",
        "    def get_fitnesses(self):\n",
        "        \"\"\"Returns an array of agent fitnesses.\"\"\"\n",
        "        fits = [agent.fitness for agent in self.agents]\n",
        "        return np.array(fits)\n",
        "        #Complexity O(n) where n is number of agents\n",
        "\n",
        "    def choose_dead(self, ps):\n",
        "        \"\"\"Choose which agents die in the next timestep.\n",
        "\n",
        "        ps: probability of survival for each agent\n",
        "\n",
        "        returns: indices of the chosen ones\n",
        "        \"\"\"\n",
        "        n = len(self.agents)\n",
        "        is_dead = np.random.random(n) < 0.1\n",
        "        index_dead = np.nonzero(is_dead)[0]\n",
        "        return index_dead\n",
        "        #Complexity O(n) where n is number of agents in the array\n",
        "\n",
        "    def choose_replacements(self, n, weights):\n",
        "        \"\"\"Choose which agents reproduce in the next timestep.\n",
        "\n",
        "        n: number of choices\n",
        "        weights: array of weights\n",
        "\n",
        "        returns: sequence of Agent objects\n",
        "        \"\"\"\n",
        "        agents = np.random.choice(self.agents, size=n, replace=True)\n",
        "        replacements = [agent.copy() for agent in agents]\n",
        "        return replacements\n",
        "        #Complexity O(n) where n is number of choices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WlkxPDHDxAYw"
      },
      "outputs": [],
      "source": [
        "class Instrument:\n",
        "    \"\"\"Computes a metric at each timestep.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.metrics = []\n",
        "        #Complexity O(1)\n",
        "\n",
        "    def update(self, sim):\n",
        "        \"\"\"Compute the current metric.\n",
        "\n",
        "        Appends to self.metrics.\n",
        "\n",
        "        sim: Simulation object\n",
        "        \"\"\"\n",
        "        # child classes should implement this method\n",
        "        pass\n",
        "        #Complexity O(1)\n",
        "\n",
        "    def plot(self, **options):\n",
        "        plt.plot(self.metrics, **options)\n",
        "        #Complexity O(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SyTEucD6xAYx"
      },
      "outputs": [],
      "source": [
        "class MeanFitness(Instrument):\n",
        "    \"\"\"Computes mean fitness at each timestep.\"\"\"\n",
        "    label = 'Mean fitness'\n",
        "\n",
        "    def update(self, sim):\n",
        "        mean = np.nanmean(sim.get_fitnesses())\n",
        "        self.metrics.append(mean)\n",
        "        #Complexity O(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "53495aVXxAYv",
        "outputId": "0aaa9a8d-44c2-4884-d38c-1aa80b7d9c29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-09 19:26:44--  https://raw.githubusercontent.com/AllenDowney/ThinkComplexity2/master/notebooks/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2645 (2.6K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]   2.58K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-09 19:26:44 (38.0 MB/s) - ‘utils.py’ saved [2645/2645]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not os.path.exists('utils.py'):\n",
        "    !wget https://raw.githubusercontent.com/AllenDowney/ThinkComplexity2/master/notebooks/utils.py\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "from utils import decorate\n",
        "\n",
        "# I set the random seed so the notebook\n",
        "# produces the same results every time.\n",
        "np.random.seed(17)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOVmpecYxAYx"
      },
      "source": [
        "### PD Agent\n",
        "\n",
        "The genome of a Prisoner's Dilemma-playing agent is a map from the previous choices of the opponent to the agent's next choice.\n",
        "\n",
        "For Agent Class defintions, the time complexity is O(1) or constant, since the length of time to set up is never dependant on the input, and neither is the mutations.\n",
        "\n",
        "*See comment below each method to for found complexity.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7F2U8OlrxAYx"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "\n",
        "    keys = [(None, None),\n",
        "            (None, 'C'),\n",
        "            (None, 'D'),\n",
        "            ('C', 'C'),\n",
        "            ('C', 'D'),\n",
        "            ('D', 'C'),\n",
        "            ('D', 'D')]\n",
        "\n",
        "    def __init__(self, values, fitness=np.nan):\n",
        "        \"\"\"Initialize the agent.\n",
        "\n",
        "        values: sequence of 'C' and 'D'\n",
        "        \"\"\"\n",
        "        self.values = values\n",
        "        self.responses = dict(zip(self.keys, values))\n",
        "        self.fitness = fitness\n",
        "        #Complexity O(1)\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset variables before a sequence of games.\n",
        "        \"\"\"\n",
        "        self.hist = [None, None]\n",
        "        self.score = 0\n",
        "        #Complexity O(1)\n",
        "\n",
        "    def past_responses(self, num=2):\n",
        "        \"\"\"Select the given number of most recent responses.\n",
        "\n",
        "        num: integer number of responses\n",
        "\n",
        "        returns: sequence of 'C' and 'D'\n",
        "        \"\"\"\n",
        "        return tuple(self.hist[-num:])\n",
        "        #Complexity O(n) where n is the memory of the agents\n",
        "\n",
        "    def respond(self, other):\n",
        "        \"\"\"Choose a response based on the opponent's recent responses.\n",
        "\n",
        "        other: Agent\n",
        "\n",
        "        returns: 'C' or 'D'\n",
        "        \"\"\"\n",
        "        key = other.past_responses()\n",
        "        resp = self.responses[key]\n",
        "        return resp\n",
        "        #Complexity O(1)\n",
        "\n",
        "    def append(self, resp, pay):\n",
        "        \"\"\"Update based on the last response and payoff.\n",
        "\n",
        "        resp: 'C' or 'D'\n",
        "        pay: number\n",
        "        \"\"\"\n",
        "        self.hist.append(resp)\n",
        "        self.score += pay\n",
        "        #Complexity O(1)\n",
        "\n",
        "    def copy(self, prob_mutate=0.05):\n",
        "        \"\"\"Make a copy of this agent.\n",
        "        \"\"\"\n",
        "        if np.random.random() > prob_mutate:\n",
        "            values = self.values\n",
        "        else:\n",
        "            values = self.mutate()\n",
        "        return Agent(values, self.fitness)\n",
        "        #Complexity O(1)\n",
        "\n",
        "    def mutate(self):\n",
        "        \"\"\"Makes a copy of this agent's values, with one mutation.\n",
        "\n",
        "        returns: sequence of 'C' and 'D'\n",
        "        \"\"\"\n",
        "        values = list(self.values)\n",
        "        index = np.random.choice(len(values))\n",
        "        values[index] = 'C' if values[index] == 'D' else 'D'\n",
        "        return values\n",
        "        #Complexity O(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Special Agents\n",
        "\n",
        "This section holds genomes for agents that are premade, such as full cooperation, TfT, and our own additions."
      ],
      "metadata": {
        "id": "AStGVt9eBsB9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRn0lhI6xAYx"
      },
      "source": [
        "Here's the genome for \"always cooperate\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M37UFl42xAYx",
        "outputId": "67eb5505-8ae3-49e2-ff9e-f104600f5050",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(None, None): 'C',\n",
              " (None, 'C'): 'C',\n",
              " (None, 'D'): 'C',\n",
              " ('C', 'C'): 'C',\n",
              " ('C', 'D'): 'C',\n",
              " ('D', 'C'): 'C',\n",
              " ('D', 'D'): 'C'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "all_c = Agent('CCCCCCC')\n",
        "all_c.responses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl2-p8tcxAYy"
      },
      "source": [
        "And for \"always defect\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r6edX1QKxAYy",
        "outputId": "8b3090ca-4344-449e-99cf-52c80c1f9a06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(None, None): 'D',\n",
              " (None, 'C'): 'D',\n",
              " (None, 'D'): 'D',\n",
              " ('C', 'C'): 'D',\n",
              " ('C', 'D'): 'D',\n",
              " ('D', 'C'): 'D',\n",
              " ('D', 'D'): 'D'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "all_d = Agent('DDDDDDD')\n",
        "all_d.responses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "istIDaiQxAYy"
      },
      "source": [
        "And for \"tit for tat\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s8sNyiT1xAYy",
        "outputId": "2ce054f6-c658-41ef-e3bb-cab5ab3cc3f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(None, None): 'C',\n",
              " (None, 'C'): 'C',\n",
              " (None, 'D'): 'D',\n",
              " ('C', 'C'): 'C',\n",
              " ('C', 'D'): 'D',\n",
              " ('D', 'C'): 'C',\n",
              " ('D', 'D'): 'D'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tft = Agent('CCDCDCD')\n",
        "tft.responses"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And For No Forgiveness #Added"
      ],
      "metadata": {
        "id": "tx2h66LK7ejC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nf = Agent('CCDCDDD')\n",
        "nf.responses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmAUVKCi7nhU",
        "outputId": "2f8db8db-c97b-48a7-c830-e0a15ae9b7e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(None, None): 'C',\n",
              " (None, 'C'): 'C',\n",
              " (None, 'D'): 'D',\n",
              " ('C', 'C'): 'C',\n",
              " ('C', 'D'): 'D',\n",
              " ('D', 'C'): 'D',\n",
              " ('D', 'D'): 'D'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And For \"Backstabbing\" #Added"
      ],
      "metadata": {
        "id": "Y_gsZ6ZW8fXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "back = Agent('CDCDCDC')\n",
        "back.responses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQRQ0c558i1y",
        "outputId": "4fe2d4c1-1d1a-46c6-8222-cd0aa59f55e3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(None, None): 'C',\n",
              " (None, 'C'): 'D',\n",
              " (None, 'D'): 'C',\n",
              " ('C', 'C'): 'D',\n",
              " ('C', 'D'): 'C',\n",
              " ('D', 'C'): 'D',\n",
              " ('D', 'D'): 'C'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And For Start Defection #Added"
      ],
      "metadata": {
        "id": "c2GFNwiyE4bG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "StartDef = Agent(\"DCCCCCC\")\n",
        "StartDef.responses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daJWk96PsHcP",
        "outputId": "9605ea67-ec8f-41ca-fe85-f13bf52d6834"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(None, None): 'D',\n",
              " (None, 'C'): 'C',\n",
              " (None, 'D'): 'C',\n",
              " ('C', 'C'): 'C',\n",
              " ('C', 'D'): 'C',\n",
              " ('D', 'C'): 'C',\n",
              " ('D', 'D'): 'C'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzR6Lrs3xAYz"
      },
      "source": [
        "The `copy` method has some probability of generating a mutation (in this example, `values` is initially a string; after mutation, it's a NumPy array of letters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [],
        "id": "mut5SyMExAYz",
        "outputId": "1f3b86d6-e9f5-48e6-8be0-1c3953041aca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DDDDDDD\n",
            "DDDDDDD\n",
            "DDDDDDD\n",
            "DDDDDDD\n",
            "DDDDDDD\n",
            "DDDDDDD\n",
            "DDDDDDD\n",
            "DDDDDDD\n",
            "['D', 'C', 'D', 'D', 'D', 'D', 'D']\n",
            "['D', 'D', 'C', 'D', 'D', 'D', 'D']\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(17)\n",
        "for i in range(10):\n",
        "    print(all_d.copy().values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vhiaKmsvxAYz",
        "outputId": "bd464963-0f8e-4813-b1ec-cea4bf241ba6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "np.sum([all_d.copy().values != all_d.values for i in range(1000)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVkYEHTYxAYz"
      },
      "source": [
        "### The Tournament\n",
        "\n",
        "`Tournament` encapsulates the rules for the tournament.\n",
        "\n",
        "Most of this code has a complexity of O(n) because each of these runs for the length of steps, or uses an array of agents to do what it needs.\n",
        "\n",
        "*See comment below each method to for found complexity.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KC3C0xV0xAYz"
      },
      "outputs": [],
      "source": [
        "class Tournament:\n",
        "\n",
        "    payoffs = {('C', 'C'): (3, 3),\n",
        "               ('C', 'D'): (0, 5),\n",
        "               ('D', 'C'): (5, 0),\n",
        "               ('D', 'D'): (1, 1)}\n",
        "\n",
        "    num_rounds = 6\n",
        "\n",
        "    def play(self, agent1, agent2):\n",
        "        \"\"\"Play a sequence of iterated PD rounds.\n",
        "\n",
        "        agent1: Agent\n",
        "        agent2: Agent\n",
        "\n",
        "        returns: tuple of agent1's score, agent2's score\n",
        "        \"\"\"\n",
        "        agent1.reset()\n",
        "        agent2.reset()\n",
        "\n",
        "        for i in range(self.num_rounds):\n",
        "            resp1 = agent1.respond(agent2)\n",
        "            resp2 = agent2.respond(agent1)\n",
        "\n",
        "            pay1, pay2 = self.payoffs[resp1, resp2]\n",
        "\n",
        "            agent1.append(resp1, pay1)\n",
        "            agent2.append(resp2, pay2)\n",
        "\n",
        "        return agent1.score, agent2.score\n",
        "\n",
        "        #Complexity O(n) where n is the number of rounds in the tournament\n",
        "\n",
        "    def melee(self, agents, randomize=True):\n",
        "        \"\"\"Play each agent against two others.\n",
        "\n",
        "        Assigns the average score from the two games to agent.fitness\n",
        "\n",
        "        agents: sequence of Agents\n",
        "        randomize: boolean, whether to shuffle the agents\n",
        "        \"\"\"\n",
        "        if randomize:\n",
        "            agents = np.random.permutation(agents)\n",
        "\n",
        "        n = len(agents)\n",
        "        i_row = np.arange(n)\n",
        "        j_row = (i_row + 1) % n\n",
        "\n",
        "        totals = np.zeros(n)\n",
        "\n",
        "        for i, j in zip(i_row, j_row):\n",
        "            agent1, agent2 = agents[i], agents[j]\n",
        "            score1, score2 = self.play(agent1, agent2)\n",
        "            totals[i] += score1\n",
        "            totals[j] += score2\n",
        "\n",
        "        for i in i_row:\n",
        "            agents[i].fitness = totals[i] / self.num_rounds / 2\n",
        "\n",
        "        #Complexity O(n) where n is the number of agents to play two other agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsWGdiAHxAY0"
      },
      "source": [
        "### Probability of survival\n",
        "\n",
        "We need a function to map from points per round (0 to 5) to probability of survival (0 to 1).  I'll use a logistic curve.\n",
        "\n",
        "This section is made up of calcuations as such all of it is O(1).\n",
        "\n",
        "*See comment below each method to for found complexity.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fzDODfUsxAY0"
      },
      "outputs": [],
      "source": [
        "def logistic(x, A=0, B=1, C=1, M=0, K=1, Q=1, nu=1):\n",
        "    \"\"\"Computes the generalize logistic function.\n",
        "\n",
        "    A: controls the lower bound\n",
        "    B: controls the steepness of the transition\n",
        "    C: not all that useful, AFAIK\n",
        "    M: controls the location of the transition\n",
        "    K: controls the upper bound\n",
        "    Q: shift the transition left or right\n",
        "    nu: affects the symmetry of the transition\n",
        "\n",
        "    returns: float or array\n",
        "    \"\"\"\n",
        "    exponent = -B * (x - M)\n",
        "    denom = C + Q * np.exp(exponent)\n",
        "    return A + (K-A) / denom ** (1/nu)\n",
        "    #Complexity O(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uGp9isZcxAY0"
      },
      "outputs": [],
      "source": [
        "def prob_survive(scores):\n",
        "    \"\"\"Probability of survival, based on fitness.\n",
        "\n",
        "    scores: sequence of scores, 0-60\n",
        "\n",
        "    returns: probability\n",
        "    \"\"\"\n",
        "    return logistic(scores, A=0.7, B=1.5, M=2.5, K=0.9)\n",
        "    #Complexity O(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sV40OKIwxAY0",
        "outputId": "4c671e6e-0a6e-467c-bb6b-71c8c22e71ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABkfklEQVR4nO3deVxVdf7H8dcFZd8EBERR3HIXFZVcKk0a1MayzNzKJbXs51JSM2m5pFZU05g1ajYzaouaZplNabaQWha54L6ROy6A4AICst77+4O6zR1RuQoelvfz8biPON+zfY4kvjnnfL9fk8VisSAiIiIiFZ6D0QWIiIiISOlQsBMRERGpJBTsRERERCoJBTsRERGRSkLBTkRERKSSULATERERqSQU7EREREQqCQU7ERERkUqimtEFVFRms5kzZ87g6emJyWQyuhwRERGppCwWC5cuXSI4OBgHh2vfk1Owu0FnzpwhJCTE6DJERESkijh58iR16tS55jYKdjfI09MTKPpD9vLyMrgaERERqawyMjIICQmxZo9rUbC7Qb8/fvXy8lKwExERkTJXkle/1HlCREREpJJQsBMRERGpJAwPdvPmzSM0NBQXFxciIiLYsmXLVbfNz89n5syZNGzYEBcXF8LCwli3bp3dx8zJyWHs2LH4+fnh4eFBv379SElJKfVrExEREbmVDA12K1asIDo6munTp7N9+3bCwsKIiori7NmzxW4/ZcoU3n33Xf7xj3+wf/9+xowZwwMPPMCOHTvsOubEiRP54osvWLlyJRs3buTMmTM8+OCDZX69IiIiImXJZLFYLEadPCIigg4dOjB37lygaGy4kJAQxo8fz6RJk67YPjg4mBdeeIGxY8da2/r164erqytLliwp0THT09OpWbMmy5Yt46GHHgLg4MGDNGvWjLi4OG6//fYS1Z6RkYG3tzfp6enqPCEiIiJlxp7MYdgdu7y8POLj44mMjPyjGAcHIiMjiYuLK3af3NxcXFxcbNpcXV3ZtGlTiY8ZHx9Pfn6+zTZNmzalbt26Vz2viIiISEVgWLBLS0ujsLCQwMBAm/bAwECSk5OL3ScqKorZs2dz6NAhzGYz3377LatWrSIpKanEx0xOTsbJyQkfH58SnxeKQmVGRobNR0RERKQ8MbzzhD3eeustGjduTNOmTXFycmLcuHGMGDHiutNrlIaYmBi8vb2tH806ISIiIuWNYcHO398fR0fHK3qjpqSkEBQUVOw+NWvWZPXq1WRlZXHixAkOHjyIh4cHDRo0KPExg4KCyMvL4+LFiyU+L8DkyZNJT0+3fk6ePGnvJYuIiIiUKcOCnZOTE+Hh4cTGxlrbzGYzsbGxdOrU6Zr7uri4ULt2bQoKCvj000+5//77S3zM8PBwqlevbrNNQkICiYmJ1zyvs7OzdZYJzTYhIiIi5ZGhU4pFR0czbNgw2rdvT8eOHZkzZw5ZWVmMGDECgKFDh1K7dm1iYmIA2Lx5M6dPn6ZNmzacPn2aF198EbPZzF//+tcSH9Pb25uRI0cSHR2Nr68vXl5ejB8/nk6dOpW4R6yIiIhIeWRosBswYACpqalMmzaN5ORk2rRpw7p166ydHxITE23en8vJyWHKlCkcPXoUDw8PevfuzYcffmjTEeJ6xwR48803cXBwoF+/fuTm5hIVFcX8+fNv2XWLiIiIlAVDx7GryDSOnYiIiNwKFWIcOxEREZHKIreg0OgSAIMfxYqIiIhUBBaLhQvZ+Rw/l8XxtCyOn8vmeFoWJ84Vfd21sT/zBrczukwFOxEREZHf5eQXcjQ1i0NnL3HkbGZRgPstzGXkFFx1vxPnsm5hlVenYCciIiJVzuW8Qo6kZnLo7CUOpWRy6Gwmh89mcuJcFmY7eh+YTBDs7Uqwt2vZFWsHBTsRERGptCwWC0npOew/k8G+MxnsO5POweRLnLyQTUm7j/4e3ur7u1PPz+23/7pT39+NOjXccKnuWLYXYQcFOxEREakUCs0WjqVl/hbgMn4Lc+lcyM4v0f6u1R1pFOBB4wAPGgV60KimBw1quhPi64ZztfIT3q5FwU5EREQqpOT0HHYkXmB74gV2JF5k75l0cvLN193PzcmxKLwFeHJboAeNAz1oHOBJbR9XHBxMt6DysqNgJyIiIuVeTn4h+86ksyPxojXIJaXnXHc/fw8nmgd70yLY67ePN/V83Sp8gLsaBTsREREpd9Iv57P12Hnijp5j2/Hz7E/KIL/w2i/Fhfi60tIa4or+W9PTGZOpcoa44ijYiYiIiOEu5eSz9fh54o6c45ej59l3Jv2avVPdnRwJC/GhbV0f2obUoE1dH/w9nG9dweWUgp2IiIjcclm5BUVB7ug5fjlyjj2nrx3kGgV40DbEh7Z1a9C2rg+3BXriWEkfp94MBTsRERG5JY6mZrI+IZUNCWfZfPQ8eYVX7+jQNMiT2xv40amhHxH1ffFxc7qFlVZcCnYiIiJSJnLyC9ly7DzfHzzLhoSzHD+XfdVtbwv0oFMDP25v4EdEAz983RXkboSCnYiIiJSapPTLfH/wLOsPnuWnw+e4nF9Y7Ha1fVy5q0lNOjcsCnN6P650KNiJiIjITTlz8TJr9ySxdk8S2xMvFruNo4OJ9vVqcHfTALo3DaBxgEeV6q16qyjYiYiIiN1KEub8PZzp3qQm3ZsG0LWxP14u1W9tkVWQgp2IiIiUyOmLl/lqTxJr9iSx4yphrkmgJ71aBdGjaSAtgr0q7UDA5ZWCnYiIiFzVpZx8vtydxCfxp4g/caHYbZoGedK7VS16t6pFowCPW1yh/DcFOxEREbFhNlv45dg5Vm47xVd7k4qdf1VhrnxSsBMREREATp7P5tPtp/gk/hSnLly+Yv1tgR70aR1M79a1aFhTYa48UrATERGpwi7nFbJuXxIrt53i5yPnrljv7Vqd+9sE0z88hJa1vdSTtZxTsBMREamCTl3I5oO4EyzfkkhGToHNOpMJ7mhck4fb1yGyWSAu1R0NqlLspWAnIiJSRVgsFjYfO897Px3nm/3JV8zNGurnRv/2ITzYrja1vF2NKVJuioKdiIhIJZeTX8h/dp1h8U/HOZCUYbPOydGBPmHBDOwYQvt6NfSotYJTsBMREamkUjJy+DDuBMu2JHI+K89mXYCnM4/eXo9BEXU1nVclomAnIiJSyfyacon56w/z5e4kCv7neWtYiA+PdQmlV8taOFVzMKhCKSsKdiIiIpXE/jMZzF1/iLV7km3aqzmY6N2qFsO7hNKubg2DqpNbQcFORESkgttzKp23vz/Et/tTbNpruFVnSEQ9Hrm9HkHeLgZVJ7eSgp2IiEgFtSPxAv/4/jDfHzxr0+7v4cyYuxowOKIubk76p74q0XdbRESkgtl2/DxvxR7ix0NpNu2BXs48eVdDBnasq7HnqigFOxERkQpi96mLvLbuID8dtp0hItjbhSe7N6J/eB0FuipOwU5ERKScO3Uhmze+TmD1zjM27SG+rozt1ogH29VRD1cBFOxERETKrYycfN7ZcISFm46RV2C2ttfzc2Nc90b0bVub6o4KdPIHBTsREZFyJr/QzEdbEpnz3SGbgYV93KrzVI/GDImopzt0UiwFOxERkXLCYrHw3YGzxHx1gKOpWdZ2J0cHRnQJ5f+6N8LbtbqBFUp5p2AnIiJSDuw+dZGX1xxg87HzNu33hQXzl6gmhPi6GVSZVCQKdiIiIgZKv5zP6+sOsmxLIpb/mv2rQ2gNXri3OW1CfAyrTSoeBTsREREDWCwWvtydxMwv95N6KdfaHurnxqRezYhqEYjJZDKwQqmIDH/zct68eYSGhuLi4kJERARbtmy55vZz5syhSZMmuLq6EhISwsSJE8nJybGuDw0NxWQyXfEZO3asdZtu3bpdsX7MmDFldo0iIiL/7eT5bIYv3sr4j3ZYQ52bkyNT7m3GNxPvomfLIIU6uSGG3rFbsWIF0dHRLFiwgIiICObMmUNUVBQJCQkEBARcsf2yZcuYNGkSixYtonPnzvz6668MHz4ck8nE7NmzAdi6dSuFhYXWffbu3cs999xD//79bY41evRoZs6caV12c9O7CyIiUrbyC80s3HSMOd/9Sk7+H8OXRDYLZOb9LQj2cTWwOqkMDA12s2fPZvTo0YwYMQKABQsWsGbNGhYtWsSkSZOu2P7nn3+mS5cuDB48GCi6Ozdo0CA2b95s3aZmzZo2+7z66qs0bNiQu+66y6bdzc2NoKCg0r4kERGRYsWfuMALn+3hYPIla1uQlwsz7m9BVAv9eySlw7BHsXl5ecTHxxMZGflHMQ4OREZGEhcXV+w+nTt3Jj4+3vq49ujRo6xdu5bevXtf9RxLlizhscceu+KW9tKlS/H396dly5ZMnjyZ7Ozsa9abm5tLRkaGzUdEROR60i/nM2X1Hh5a8LM11DmYYESXUL575i6FOilVht2xS0tLo7CwkMDAQJv2wMBADh48WOw+gwcPJi0tja5du2KxWCgoKGDMmDE8//zzxW6/evVqLl68yPDhw684Tr169QgODmb37t0899xzJCQksGrVqqvWGxMTw4wZM+y7SBERqdK+P5jCc5/usekc0SLYi5gHW9G6jo9xhUmlVaF6xW7YsIFXXnmF+fPnExERweHDh3nqqaeYNWsWU6dOvWL7hQsX0qtXL4KDg23aH3/8cevXrVq1olatWvTo0YMjR47QsGHDYs89efJkoqOjrcsZGRmEhISU0pWJiEhlkp1XwMtrDrB0c6K1zc3Jkeh7bmN451CqaRowKSOGBTt/f38cHR1JSUmxaU9JSbnqu29Tp07l0UcfZdSoUUBRKMvKyuLxxx/nhRdewMHhj78oJ06c4LvvvrvmXbjfRUREAHD48OGrBjtnZ2ecnZ1LdG0iIlJ17Tp5kYkrdnI07Y+ZI7o1qcnLD7SitjpHSBkz7FcGJycnwsPDiY2NtbaZzWZiY2Pp1KlTsftkZ2fbhDcAR0dHoGg8oP+2ePFiAgICuPfee69by86dOwGoVauWPZcgIiJiVVBo5u3YQzz4zs/WUOdS3YGX+rZk8fAOCnVySxj6KDY6Opphw4bRvn17OnbsyJw5c8jKyrL2kh06dCi1a9cmJiYGgD59+jB79mzatm1rfRQ7depU+vTpYw14UBQQFy9ezLBhw6hWzfYSjxw5wrJly+jduzd+fn7s3r2biRMncuedd9K6detbd/EiIlJpnDiXxcQVO9meeNHaFlbHmzcHtKFBTQ/jCpMqx9BgN2DAAFJTU5k2bRrJycm0adOGdevWWTtUJCYm2tyhmzJlCiaTiSlTpnD69Glq1qxJnz59ePnll22O+91335GYmMhjjz12xTmdnJz47rvvrCEyJCSEfv36MWXKlLK9WBERqXQsFgsfbzvJjC/2k51XNIaqgwnG3d2Y8Xc3orrepZNbzGT532eYUiIZGRl4e3uTnp6Ol5eX0eWIiMgtdi4zl8mr9vDN/j/eFa/n58bsh9sQXq+GgZVJZWNP5qhQvWJFRETKg58PpzFh+U7SMv8YxmRghxCm/rk57s76p1WMo//7RERESshisfDuD0d5fd1BzL897/J1d+LVB1vxJw00LOWAgp2IiEgJXMrJ5y8rd7NuX7K17Y7G/vz94TACPF0MrEzkDwp2IiIi1/FryiXGfBhvMzbdUz0aM6FHYxwdTNfYU+TWUrATERG5hi92neG5T3dbe716uVRjzsA23N008Dp7itx6CnYiIiLFyC80E7P2IIt+OmZta1bLi3cfCaeun5uBlYlcnYKdiIjI/zh7KYdxS3ew5fh5a1u/dnV4qW9LXJ0cr7GniLEU7ERERP7L1uPnGbt0O2cvFQ1lUt3RxIv3tWBwx7qYTHqfTso3BTsREZHffLQlkamr91Lw21gmtbxdmD+kHW3rasBhqRgU7EREpMozmy289vVB3t141NrWuaEf/xjUFj8PZwMrE7GPgp2IiFRpOfmFPPPxLtbsSbK2jepan0m9mlJNc71KBaNgJyIiVda5zFxGf7CN7YkXAXAwwYz7W/Lo7fWMLUzkBinYiYhIlXQkNZMRi7eSeD4bADcnR+YNbkf3pgEGVyZy4xTsRESkytl89ByPfxhP+uV8AAK9nFk4rAMta3sbXJnIzVGwExGRKmX1jtP89ZPd5BWaAWga5MniER2o5e1qcGUiN0/BTkREqgSLxcLc7w/z929/tbbddVtN5g5ui6dLdQMrEyk9CnYiIlLp5RWYef6zPXwSf8raNjiiLjPva6Ger1KpKNiJiEillpNfyJNL4lmfkGptm9yrKY/f2UAzSUilo2AnIiKVVmZuAaPe38ovR4vmfHWq5sCbD7fh3ta1DK5MpGwo2ImISKWUnp3PsMVb2HnyIgDuTo4sHN6B2xv4GVuYSBlSsBMRkUonLTOXRxdu4UBSBgDertV5/7GOtAnxMbYwkTKmYCciIpVKUvplhvx7M0dTswDw93Diw5ERNKvlZXBlImVPwU5ERCqNxHPZDP73L5y6cBmAWt4uLB0VQYOaHgZXJnJrKNiJiEilcPjsJYb8ezMpGbkA1PNzY8nICEJ83QyuTOTWUbATEZEKb+/pdIYu2sL5rDwAGgd4sGRUBIFeLgZXJnJrKdiJiEiFFn/iAsMXb+FSTgEALWt78cFjEfi6Oxlcmcitp2AnIiIV1i9Hz/HYe1vJzisEILxeDRaP6ICXpgiTKkrBTkREKqT4E+dtQl2XRn78a2h73Jz0T5tUXfq/X0REKpzdpy4yfNEfoa57k5q880g4LtUdDa5MxFia+VhERCqUA0kZPLpwC5dyi96pu6Oxv0KdyG8U7EREpMI4fPYSj/x7M+mX8wHoWN+Xfz7aXqFO5DcKdiIiUiEcT8ti8L82c+63IU3ahPiwaHgHXJ0U6kR+p2AnIiLl3qkL2Qz592bOXioafLhFsBfvP9YRD2e9Ki7y3xTsRESkXEtOz2HwvzZz+mLRNGFNAj35cGQE3q4a0kTkfynYiYhIuZV6KZfB//6FxPPZADTwd2fJKA0+LHI1CnYiIlIuXcjK49GFmzmamgVAiK8rS0dHUNPT2eDKRMovBTsRESl30i/nM3TRFg4mXwIg2NuFZaNup5a3q8GViZRvhge7efPmERoaiouLCxEREWzZsuWa28+ZM4cmTZrg6upKSEgIEydOJCcnx7r+xRdfxGQy2XyaNm1qc4ycnBzGjh2Ln58fHh4e9OvXj5SUlDK5PhERsU9OfiGjP9jGntPpAAR4OrN09O2E+LoZXJlI+WdosFuxYgXR0dFMnz6d7du3ExYWRlRUFGfPni12+2XLljFp0iSmT5/OgQMHWLhwIStWrOD555+32a5FixYkJSVZP5s2bbJZP3HiRL744gtWrlzJxo0bOXPmDA8++GCZXaeIiJSM2Wwh+uOdbDl2HgBfdyeWjoqgvr+7wZWJVAyG9hOfPXs2o0ePZsSIEQAsWLCANWvWsGjRIiZNmnTF9j///DNdunRh8ODBAISGhjJo0CA2b95ss121atUICgoq9pzp6eksXLiQZcuWcffddwOwePFimjVrxi+//MLtt99empcoIiIlZLFYmPnlftbuSQbAtboji4d3oHGgp8GViVQcht2xy8vLIz4+nsjIyD+KcXAgMjKSuLi4Yvfp3Lkz8fHx1se1R48eZe3atfTu3dtmu0OHDhEcHEyDBg0YMmQIiYmJ1nXx8fHk5+fbnLdp06bUrVv3qucFyM3NJSMjw+YjIiKl518/HuW9n48D4OhgYv6QdoSF+Bhak0hFY9gdu7S0NAoLCwkMDLRpDwwM5ODBg8XuM3jwYNLS0ujatSsWi4WCggLGjBlj8yg2IiKC9957jyZNmpCUlMSMGTO444472Lt3L56eniQnJ+Pk5ISPj88V501OTr5qvTExMcyYMePGL1hERK7q852neWXtHz/7Yx5oRfemAQZWJFIxGd55wh4bNmzglVdeYf78+Wzfvp1Vq1axZs0aZs2aZd2mV69e9O/fn9atWxMVFcXatWu5ePEiH3/88U2de/LkyaSnp1s/J0+evNnLERER4KfDaTy7cpd1Ofqe23i4Q4iBFYlUXIbdsfP398fR0fGK3qgpKSlXfT9u6tSpPProo4waNQqAVq1akZWVxeOPP84LL7yAg8OVOdXHx4fbbruNw4cPAxAUFEReXh4XL160uWt3rfMCODs74+yssZNERErT/jMZPPFhPPmFFgAGdazL+LsbGVyVSMVl2B07JycnwsPDiY2NtbaZzWZiY2Pp1KlTsftkZ2dfEd4cHYsmf7ZYLMXuk5mZyZEjR6hVqxYA4eHhVK9e3ea8CQkJJCYmXvW8IiJS+k5dyGb44i1k5hYAENksgFn3t8BkMhlcmUjFZWiv2OjoaIYNG0b79u3p2LEjc+bMISsry9pLdujQodSuXZuYmBgA+vTpw+zZs2nbti0REREcPnyYqVOn0qdPH2vAe/bZZ+nTpw/16tXjzJkzTJ8+HUdHRwYNGgSAt7c3I0eOJDo6Gl9fX7y8vBg/fjydOnVSj1gRkVvkYnYewxZt4eylXADahPjwj0HtqOZYod4QEil3DA12AwYMIDU1lWnTppGcnEybNm1Yt26dtUNFYmKizR26KVOmYDKZmDJlCqdPn6ZmzZr06dOHl19+2brNqVOnGDRoEOfOnaNmzZp07dqVX375hZo1a1q3efPNN3FwcKBfv37k5uYSFRXF/Pnzb92Fi4hUYTn5hYx6fxtHfpsqrL6/O4uGd8DVydHgykQqPpPlas8w5ZoyMjLw9vYmPT0dLy8vo8sREakQCs0W/m9pPF/vK3q/2t/DmVVPdqaun2aVELkaezKH7nmLiMgt89Ka/dZQ5+7kyHsjOijUiZQiBTsREbkllm1OZPFPxwGo5mDinUfCaVnb29iiRCoZBTsRESlzcUfOMe3zvdbllx9oyZ231bzGHiJyIxTsRESkTJ04l8WTS+MpMBe90j2ya30GdKhrcFUilZOCnYiIlJlLOfmMfH8bF7PzAbjrtppM7tXU4KpEKi8FOxERKROFZgsTPtrB4bOZADQK8OAfg9tqrDqRMqS/XSIiUiZi1h5gfUIqAD5u1fn30PZ4uVQ3uCqRyk3BTkRESt3HW0/y703HgKIesPOHtCPU393gqkQqPwU7EREpVVuOneeF1XusyzPub0Hnhv4GViRSdSjYiYhIqTl5PpsxS+LJLyzqATu8cyhDIuoZXJVI1aFgJyIipSIzt4BR72/jfFYeAHc09mfKvc0MrkqkalGwExGRm1ZotvD08h0kpFwCoIG/O3MHtVMPWJFbTH/jRETkpv39mwS+O3AWAC+Xavx7WHu83dQDVuRWU7ATEZGbsm5vMvM3HAHA0cHE/CHhNKjpYXBVIlWTgp2IiNywo6mZPLtyl3X5+d7N6NpYPWBFjKJgJyIiNyQrt4AxS+LJzC0AoE9YMI91CTW2KJEqTsFORETsZrFYeO7T3fyaUjRd2G2BHrz6YCtMJpPBlYlUbdVKstF//vOfEh/wvvvuu+FiRESkYlj803G+3J0EgIdzNRY8Eo67c4n+SRGRMlSiv4V9+/Yt0cFMJhOFhYU3U4+IiJRzW46d55W1B6zLb/QPU2cJkXKiRMHObDaXdR0iIlIBnM3IYeyy7RSYi2aWeLJbQ3q2DDK4KhH5nd6xExGREskvNDN22XZSL+UC0KWRH8/cc5vBVYnIf7uhFyKysrLYuHEjiYmJ5OXl2aybMGFCqRQmIiLlS8zag2w9fgGAWt4uvD2wrWaWECln7A52O3bsoHfv3mRnZ5OVlYWvry9paWm4ubkREBCgYCciUgn9Z9cZFv10DAAnRwfeeSQcPw9ng6sSkf9l969aEydOpE+fPly4cAFXV1d++eUXTpw4QXh4OG+88UZZ1CgiIgZKSL7Ec5/sti5Pv685bUJ8jCtIRK7K7mC3c+dOnnnmGRwcHHB0dCQ3N5eQkBBef/11nn/++bKoUUREDJKRk8+YJfFczi8a8eCh8DoM7ljX4KpE5GrsDnbVq1fHwaFot4CAABITEwHw9vbm5MmTpVudiIgYxmKx8NeVuzmWlgVA81pevNS3pQYhFinH7H7Hrm3btmzdupXGjRtz1113MW3aNNLS0vjwww9p2bJlWdQoIiIG+CDuBOv2JQPg5VI0CLFLdUeDqxKRa7H7jt0rr7xCrVq1AHj55ZepUaMGTz75JKmpqfzzn/8s9QJFROTW23s6nZfX/DEI8eyH21DXz83AikSkJOy+Y9e+fXvr1wEBAaxbt65UCxIREWNdysln3LLt5BUWDU4/smt9IpsHGlyViJSE3XfsXnrpJY4dO1YWtYiIiMEsFgvPf7aX4+eyAWhdx5vnejY1uCoRKSm7g93KlStp1KgRnTt3Zv78+aSlpZVFXSIiYoDlW0/yxa4zAHg6V2PuoHY4VdMgxCIVhd1/W3ft2sXu3bvp1q0bb7zxBsHBwdx7770sW7aM7OzssqhRRERugYPJGbz4n33W5dceaq336kQqGJPFYrHczAF++uknli1bxsqVK8nJySEjI6O0aivXMjIy8Pb2Jj09HS8vL6PLERG5Kdl5BfT5xyaOpBYNbfLo7fWY1VcjHYiUB/Zkjpu+v+7u7o6rqytOTk7k5+ff7OFERMQA0z7fZw11zWp58cK9zQyuSERuxA0Fu2PHjvHyyy/TokUL2rdvz44dO5gxYwbJycmlXZ+IiJSxT+NP8Un8KQDcnByZN7itxqsTqaDsHu7k9ttvZ+vWrbRu3ZoRI0YwaNAgateuXRa1iYhIGTt8NpOpn++1Lr/yQCsa1PQwsCIRuRl2B7sePXqwaNEimjdvXhb1iIjILZKTX8i4ZdvJziuaB/bh9nXo21a/qItUZHY/in355ZdLNdTNmzeP0NBQXFxciIiIYMuWLdfcfs6cOTRp0gRXV1dCQkKYOHEiOTk51vUxMTF06NABT09PAgIC6Nu3LwkJCTbH6NatGyaTyeYzZsyYUrsmEZGKYOaX+zmYfAmAxgEezLhPnSVEKroS3bGLjo5m1qxZuLu7Ex0dfc1tZ8+eXeKTr1ixgujoaBYsWEBERARz5swhKiqKhIQEAgICrth+2bJlTJo0iUWLFtG5c2d+/fVXhg8fjslksp5348aNjB07lg4dOlBQUMDzzz/Pn/70J/bv34+7u7v1WKNHj2bmzJnWZTc3dekXkarji11nWLY5EQCX6g7MG9IOVye9VydS0ZUo2O3YscPa43XHjh1X3c5kMtl18tmzZzN69GhGjBgBwIIFC1izZg2LFi1i0qRJV2z/888/06VLFwYPHgxAaGgogwYNYvPmzdZt/neKs/fee4+AgADi4+O58847re1ubm4EBQXZVa+ISGVw8nw2z6/aY12eeV9Lbgv0NLAiESktJQp269evL/brm5GXl0d8fDyTJ0+2tjk4OBAZGUlcXFyx+3Tu3JklS5awZcsWOnbsyNGjR1m7di2PPvroVc+Tnp4OgK+vr0370qVLWbJkCUFBQfTp04epU6fqrp2IVHoFhWYmrtjJpdwCAO4LC6Z/+zoGVyUipcXuzhNLlizhwQcfvOkQlJaWRmFhIYGBthNLBwYGcvDgwWL3GTx4MGlpaXTt2hWLxUJBQQFjxozh+eefL3Z7s9nM008/TZcuXWjZsqXNcerVq0dwcDC7d+/mueeeIyEhgVWrVl213tzcXHJzc63LVWUgZhGpXOZvOMK2ExcAqFPDlZceaGn30xYRKb/s7jwxceJEAgICGDx4MGvXrqWwsLAs6irWhg0beOWVV5g/fz7bt29n1apVrFmzhlmzZhW7/dixY9m7dy/Lly+3aX/88ceJioqiVatWDBkyhA8++IDPPvuMI0eOXPXcMTExeHt7Wz8hISGlem0iImUt/sQF3oo9BICDCeYMaIOXS3WDqxKR0mR3sEtKSmL58uWYTCYefvhhatWqxdixY/n555/tOo6/vz+Ojo6kpKTYtKekpFz13bepU6fy6KOPMmrUKFq1asUDDzzAK6+8QkxMDGaz2WbbcePG8eWXX7J+/Xrq1Ln2Y4aIiAgADh8+fNVtJk+eTHp6uvVz8uTJklymiEi5cCknn6dX7KDQXDSL5Pi7G9M+1Pc6e4lIRWN3sKtWrRp//vOfWbp0KWfPnuXNN9/k+PHjdO/enYYNG5b4OE5OToSHhxMbG2ttM5vNxMbG0qlTp2L3yc7OxsHBtmRHx6JeXL9PeWuxWBg3bhyfffYZ33//PfXr179uLTt37gSgVq1aV93G2dkZLy8vm4+ISEUx/T/7OHn+MgDt6vow/u5GBlckImXB7nfs/pubmxtRUVFcuHCBEydOcODAAbv2j46OZtiwYbRv356OHTsyZ84csrKyrL1khw4dSu3atYmJiQGgT58+zJ49m7Zt2xIREcHhw4eZOnUqffr0sQa8sWPHsmzZMj7//HM8PT2t05x5e3vj6urKkSNHWLZsGb1798bPz4/du3czceJE7rzzTlq3bn0zfxwiIuXSf3adYdX20wB4OFfjrYFtqeZ401OFi0g5dEPBLjs7m88++4ylS5cSGxtLSEgIgwYN4pNPPrHrOAMGDCA1NZVp06aRnJxMmzZtWLdunbVDRWJios0duilTpmAymZgyZQqnT5+mZs2a9OnTh5dfftm6zTvvvAMUDUL83xYvXszw4cNxcnLiu+++s4bIkJAQ+vXrx5QpU27kj0JEpFw7dSGbFz77Y2iTWX1bEOKrEQBEKiuT5fdnmCU0cOBAvvzyS9zc3Hj44YcZMmTIVR+dVmYZGRl4e3uTnp6ux7IiUi4Vmi0M/GccW48X9YK9v00wbw1sa3BVImIvezKH3XfsHB0d+fjjj4mKirI+/hQRkfJn/vrD1lBX28eVWX01ZZhIZWfXSxb5+fkkJyfTuHFjhToRkXJse+IF5vzX0CZvDdTQJiJVgV3Brnr16uzevbusahERkVKQmVvA08t3Woc2GaehTUSqDLu7RT3yyCMsXLiwLGoREZFSMP3zfSSezwagbV0fJmhoE5Eqw+537AoKCli0aBHfffcd4eHhuLu726yfPXt2qRUnIiL2+WLXGT7dfgr4bWiTARraRKQqsTvY7d27l3bt2gHw66+/2qzTfIMiIsZJSr9sM7TJzPtbUNdPQ5uIVCV2B7v169eXRR0iInITzGYLf1m5m4ycAgD6hAXzQNvaBlclIrea7s+LiFQCH8QdZ9PhNACCvFx46f6WeooiUgXZfceue/fu1/xh8f33399UQSIiYp/DZy8R89VB6/Lf+rfG201Dm4hURXYHuzZt2tgs5+fns3PnTvbu3cuwYcNKqy4RESmB/EIzE1fsIrfADMDwzqHc0bimwVWJiFHsDnZvvvlmse0vvvgimZmZN12QiIiU3D9iD7HndDoADWu681zPpgZXJCJGKrV37B555BEWLVpUWocTEZHr2J54gbnrDwNQzcHEmwPa4OqkWYFEqrJSC3ZxcXG4uLiU1uFEROQasvMKiF6xk98ml2BCj8a0ruNjaE0iYjy7H8U++OCDNssWi4WkpCS2bdvG1KlTS60wERG5upfXHOD4uaLZJdqE+PB/3RoaXJGIlAd2Bztvb2+bZQcHB5o0acLMmTP505/+VGqFiYhI8dYnnGXp5kQAXKs78uaANppdQkSAGwh2ixcvLos6RESkBM5n5fHXT3Zbl1+4txn1/d2vsYeIVCV2/4p38uRJTp06ZV3esmULTz/9NP/85z9LtTAREbFlsVh44bM9pF7KBaBbk5oMiahrcFUiUp7YHewGDx5snVYsOTmZyMhItmzZwgsvvMDMmTNLvUARESny2Y7TfLU3GQAft+q83q+1ZpcQERt2B7u9e/fSsWNHAD7++GNatWrFzz//zNKlS3nvvfdKuz4REQFOX7zM9M/3WZdfeaAVAV4aiUBEbNkd7PLz83F2dgbgu+++47777gOgadOmJCUllW51IiKC2Wzh2Y93cSm3AIAH29amd6taBlclIuWR3cGuRYsWLFiwgB9//JFvv/2Wnj17AnDmzBn8/PxKvUARkaru/bjjxB09B0Cwtwsv3t/C4IpEpLyyO9i99tprvPvuu3Tr1o1BgwYRFhYGwH/+8x/rI1oRESkdR1IzefWrg9blN/qH4eVS3cCKRKQ8s3u4k27dupGWlkZGRgY1atSwtj/++OO4ubmVanEiIlVZQaGZZz7eRW6BGYDhnUPp3Mjf4KpEpDyzO9gBODo62oQ6gNDQ0NKoR0REfvPuD0fZefIiAPX93XmuZ1NjCxKRck9DlYuIlEP7z2Qw57tfAXAwFT2CdXVyNLgqESnvFOxERMqZvAIz0R/vJL/QAsATdzUkvF6N6+wlIqJgJyJS7rwde4iDyZcAaBrkydORjQ2uSEQqihIFO19fX9LS0gB47LHHuHTpUpkWJSJSVe1IvMD8DYcBqOZg4u8Ph+FcTY9gRaRkShTs8vLyyMjIAOD9998nJyenTIsSEamKLucV8szHuzAXPYHlqR6NaRHsbWxRIlKhlKhXbKdOnejbty/h4eFYLBYmTJiAq6trsdsuWrSoVAsUEakqXv/6IEfTsgAIq+PNk90aGlyRiFQ0JQp2S5Ys4c033+TIkSOYTCbS09N1105EpBT9fCSNxT8dB8C5mgN/f7gN1Rz1GrSI2MdksVgs9uxQv359tm3bVuWnD8vIyMDb25v09HS8vLyMLkdEKrDM3AKi3vyB0xcvAzD1z80Z2bW+wVWJSHlhT+awe4DiY8eO3XBhIiJypZe+3G8NdRH1fRnROdTYgkSkwrqh+/wbN26kT58+NGrUiEaNGnHffffx448/lnZtIiKV3vqDZ1m+9SQA7k6OvNE/DAcHk8FViUhFZXewW7JkCZGRkbi5uTFhwgRrR4oePXqwbNmysqhRRKRSupidx3Of7rYuT/lzc0J8Nee2iNw4u9+xa9asGY8//jgTJ060aZ89ezb/+te/OHDgQKkWWF7pHTsRuVlPLd/B5zvPAHDXbTV5b0QHTCbdrRMRW/ZkDrvv2B09epQ+ffpc0X7ffffp/TsRkRL6ak+SNdR5uVTjtX6tFepE5KbZHexCQkKIjY29ov27774jJCSkVIoSEanM0jJzeWH1XuvyjPtbEOTtYmBFIlJZ2B3snnnmGSZMmMCTTz7Jhx9+yIcffsiYMWN4+umnefbZZ+0uYN68eYSGhuLi4kJERARbtmy55vZz5syhSZMmuLq6EhISwsSJE68YU+96x8zJyWHs2LH4+fnh4eFBv379SElJsbt2ERF7WSwWpny2l/NZeQBEtQikb5vaBlclIpWG5QasWrXK0qVLF4uvr6/F19fX0qVLF8vq1avtPs7y5cstTk5OlkWLFln27dtnGT16tMXHx8eSkpJS7PZLly61ODs7W5YuXWo5duyY5euvv7bUqlXLMnHiRLuOOWbMGEtISIglNjbWsm3bNsvtt99u6dy5s121p6enWwBLenq63dctIlXXZ9tPWeo996Wl3nNfWtrO/MaSeinH6JJEpJyzJ3PY3XmiNEVERNChQwfmzp0LgNlsJiQkhPHjxzNp0qQrth83bhwHDhyweRT8zDPPsHnzZjZt2lSiY6anp1OzZk2WLVvGQw89BMDBgwdp1qwZcXFx3H777SWqXZ0nRMReKRk53DN7Ixk5BQDMH9KO3q1qGVyViJR3Zdp5orTk5eURHx9PZGTkH8U4OBAZGUlcXFyx+3Tu3Jn4+Hjro9WjR4+ydu1aevfuXeJjxsfHk5+fb7NN06ZNqVu37lXPC5Cbm0tGRobNR0SkpCwWC5M+3W0NdfeFBSvUiUips3vmidKSlpZGYWEhgYGBNu2BgYEcPHiw2H0GDx5MWloaXbt2xWKxUFBQwJgxY3j++edLfMzk5GScnJzw8fG5Ypvk5OSr1hsTE8OMGTPsvUwREQA+3naS9QmpANT0dGbm/S0MrkhEKqMKNcP0hg0beOWVV5g/fz7bt29n1apVrFmzhlmzZpX5uSdPnkx6err1c/LkyTI/p4hUDqcuZDPryz/G+Hz1wVb4uDkZWJGIVFaG3bHz9/fH0dHxit6oKSkpBAUFFbvP1KlTefTRRxk1ahQArVq1Iisri8cff5wXXnihRMcMCgoiLy+Pixcv2ty1u9Z5AZydnXF2dr6RSxWRKsxstvDXT3aTmVv0CLZ/eB16NAu8zl4iIjfG7jt269evL5UTOzk5ER4ebtMRwmw2ExsbS6dOnYrdJzs7GwcH25IdHR2BovdXSnLM8PBwqlevbrNNQkICiYmJVz2viMiNWrL5BD8fOQdAsLcLU/s0N7giEanM7L5j17NnT+rUqcOIESMYNmzYTQ1KHB0dzbBhw2jfvj0dO3Zkzpw5ZGVlMWLECACGDh1K7dq1iYmJAaBPnz7Mnj2btm3bEhERweHDh5k6dSp9+vSxBrzrHdPb25uRI0cSHR2Nr68vXl5ejB8/nk6dOpW4R6yISEkcT8siZu0f7wy//lAYXi7VDaxIRCo7u4Pd6dOn+fDDD3n//feZMWMGd999NyNHjqRv3744Odn3zsiAAQNITU1l2rRpJCcn06ZNG9atW2ft/JCYmGhzh27KlCmYTCamTJnC6dOnqVmzJn369OHll18u8TEB3nzzTRwcHOjXrx+5ublERUUxf/58e/8oRESuqtBs4dmVu7icXwjAI7fXpWtjf4OrEpHK7qbGsdu+fTuLFy/mo48+Aop6rY4cOZKwsLBSK7C80jh2InIt//rhKC+vLeowUdfXja+eugN3Z8NeaxaRCuyWjWPXrl07Jk+ezLhx48jMzGTRokWEh4dzxx13sG/fvps5tIhIhXUo5RJ/+yYBAJMJ3ugfplAnIrfEDQW7/Px8PvnkE3r37k29evX4+uuvmTt3LikpKRw+fJh69erRv3//0q5VRKTcyy80E/3xLvIKzAA81qU+Hev7GlyViFQVdv8KOX78eD766CMsFguPPvoor7/+Oi1btrSud3d354033iA4OLhUCxURqQjmrz/CntPpADQK8OAvUU0MrkhEqhK7g93+/fv5xz/+wYMPPnjVcd38/f1LbVgUEZGKYu/pdP7x/SEAHB1M/L1/GC7VHQ2uSkSqErsfxU6fPp3+/ftfEeoKCgr44YcfAKhWrRp33XVX6VQoIlIB5OQXEv3xTgrMRf3RxnZrSFiIj7FFiUiVY3ew6969O+fPn7+iPT09ne7du5dKUSIiFc2b3/3KrymZALQI9mLc3Y0NrkhEqiK7g53FYsFkMl3Rfu7cOdzd3UulKBGRimTb8fP884ejADg5OvD3h8NwqlahpuIWkUqixO/YPfjggwCYTCaGDx9u8yi2sLCQ3bt307lz59KvUESkHMvOK+CZlbv4fUTQiffcRtMgjW0pIsYocbDz9vYGiu7YeXp64urqal3n5OTE7bffzujRo0u/QhGRcuzVrw5y4lw2AO3q+vD4nQ0MrkhEqrISB7vFixcDEBoayrPPPqvHriJS5W06lMYHcScAcKnuwN8fboOjw5WvqoiI3Cp2D3cyffr0sqhDRKRCycjJ5y+f7LIuT+7VjPr++oVXRIxVomDXrl07YmNjqVGjBm3bti2288Tvtm/fXmrFiYiUVzP+s5+k9BwAujTy49Hb6xlckYhICYPd/fffb+0s0bdv37KsR0Sk3PtmXzKfbj8FgKdzNV5/KAwHPYIVkXLAZLH83pdL7JGRkYG3tzfp6el4eakHnEhVcT4rjz+9uZG0zDwA/vZQa/q3DzG4KhGpzOzJHBpoSUSkhCwWC1NW77GGushmATwUXsfgqkRE/lCiR7E1atS45nt1/624WSlERCqD1TtPs3ZPMgA13KrzyoOtSvyzUUTkVihRsJszZ04ZlyEiUr6dvniZaZ/vsy6/1LcVAZ4uBlYkInKlEgW7YcOGlXUdIiLlltls4dmPd3EppwCAB9rW5t7WtQyuSkTkSiUKdhkZGdaX9TIyMq65rToSiEhls/jn48QdPQdALW8XXryvhcEViYgUr8Tv2CUlJREQEICPj0+x75RYLBZMJhOFhYWlXqSIiFF+TbnEa+sOWpf/3j8Mb9fqBlYkInJ1JQp233//Pb6+vgCsX7++TAsSESkv8grMPL18J3kFZgBGdq1P50b+BlclInJ1JQp2d911V7Ffi4hUZm/F/sr+pKLXTxoHePCXqCYGVyQicm12zxULcOHCBRYuXMiBAwcAaN68OSNGjLDe1RMRqejiT5znnQ1HAKjuaOLNAW1wqe5ocFUiItdm9wDFP/zwA6Ghobz99ttcuHCBCxcu8Pbbb1O/fn1++OGHsqhRROSWysotYOKKXZh/m5fn6cjbaFnb29iiRERKwO47dmPHjmXAgAG88847ODoW/fZaWFjI//3f/zF27Fj27NlT6kWKiNxKL63ZT+L5bADC69XgiTsbGFyRiEjJ2H3H7vDhwzzzzDPWUAfg6OhIdHQ0hw8fLtXiRERutdgDKXy05SQAbk6OzH44jGqOmn1RRCoGu39atWvXzvpu3X87cOAAYWFhpVKUiIgRzmXm8tynu63LU//cnHp+7gZWJCJinxI9it29+48fdBMmTOCpp57i8OHD3H777QD88ssvzJs3j1dffbVsqhQRKWMWi4XJq/aQlpkHQI+mAQzsEGJwVSIi9jFZLBbL9TZycHDAZDJxvU2r0gDFGRkZeHt7k56ertk2RCqBldtO8pdPin6J9XV3Yt3Td2guWBEpF+zJHCW6Y3fs2LFSKUxEpDxKPJfNjC/2W5dfeaCVQp2IVEglCnb16tUr6zpERAxRUGjm6RU7yMwtAKBfuzr0bBlkcFUiIjfmhgYoBti/fz+JiYnk5eXZtN933303XZSIyK3y9veH2Z54EYC6vm7MuL+FsQWJiNwEu4Pd0aNHeeCBB9izZ4/Ne3cmkwmgyrxjJyIV37bj55n7/SEAHB1MzBnYBg/nG/59V0TEcHYPd/LUU09Rv359zp49i5ubG/v27eOHH36gffv2bNiwoQxKFBEpfRk5+Ty1fKd1domnejSmXd0axhYlInKT7P7VNC4uju+//x5/f38cHBxwcHCga9euxMTEMGHCBHbs2FEWdYqIlKqpq/dy+uJlADqE1mBs90YGVyQicvPsvmNXWFiIp6cnAP7+/pw5cwYo6mCRkJBQutWJiJSB1TtO8/nOop9dns7VeHNAGxwdTAZXJSJy8+y+Y9eyZUt27dpF/fr1iYiI4PXXX8fJyYl//vOfNGig+RRFpHw7eT6bKav3WpdfeqAldWq4GViRiEjpsfuO3ZQpUzCbzQDMnDmTY8eOcccdd7B27VrefvvtGypi3rx5hIaG4uLiQkREBFu2bLnqtt26dcNkMl3xuffee63bFLfeZDLxt7/9zbpNaGjoFes1c4ZI5VZQaOap5X8MbfJg29rc36a2wVWJiJQeu+/YRUVFWb9u1KgRBw8e5Pz589SoUcPaM9YeK1asIDo6mgULFhAREcGcOXOIiooiISGBgICAK7ZftWqVzRAr586dIywsjP79+1vbkpKSbPb56quvGDlyJP369bNpnzlzJqNHj7Yu//6IWUQqp7nrNbSJiFRuN9Wv/+TJkwCEhNz4fIqzZ89m9OjRjBgxAoAFCxawZs0aFi1axKRJk67Y3tfX12Z5+fLluLm52QS7oCDbwUU///xzunfvfsWjYk9Pzyu2FZHKKf7Eed6O/WNokzcHtMHTpbrBVYmIlC67H8UWFBQwdepUvL29CQ0NJTQ0FG9vb6ZMmUJ+fr5dx8rLyyM+Pp7IyMg/CnJwIDIykri4uBIdY+HChQwcOBB3d/di16ekpLBmzRpGjhx5xbpXX30VPz8/2rZty9/+9jcKCgrsql9EKob/Hdpkwt2NCa+noU1EpPKx+47d+PHjWbVqFa+//jqdOnUCioZAefHFFzl37hzvvPNOiY+VlpZGYWEhgYGBNu2BgYEcPHjwuvtv2bKFvXv3snDhwqtu8/777+Pp6cmDDz5o0z5hwgTatWuHr68vP//8M5MnTyYpKYnZs2cXe5zc3Fxyc3OtyxkZGdetT0TKh2mr93LqQtHQJu3r1WBs94YGVyQiUjbsDnbLli1j+fLl9OrVy9rWunVrQkJCGDRokF3B7mYtXLiQVq1a0bFjx6tus2jRIoYMGYKLi+2E3tHR0davW7dujZOTE0888QQxMTE4OztfcZyYmBhmzJhResWLyC2xesdpVv/P0CbVHO1+WCEiUiHY/dPN2dmZ0NDQK9rr16+Pk5OTXcfy9/fH0dGRlJQUm/aUlJTrvvuWlZXF8uXLi33E+rsff/yRhIQERo0add1aIiIiKCgo4Pjx48Wunzx5Munp6dbP7+8Xikj5deJcFlP/Z2iTEF8NbSIilZfdwW7cuHHMmjXL5rFkbm4uL7/8MuPGjbPrWE5OToSHhxMbG2ttM5vNxMbGWh/zXs3KlSvJzc3lkUceueo2CxcuJDw8nLCwsOvWsnPnThwcHIrtiQtFgdbLy8vmIyLlV25BIeOW7eDSb0ObPKChTUSkCijRo9j/fT/tu+++o06dOtbAtGvXLvLy8ujRo4fdBURHRzNs2DDat29Px44dmTNnDllZWdZeskOHDqV27drExMTY7Ldw4UL69u2Ln59fscfNyMhg5cqV/P3vf79iXVxcHJs3b6Z79+54enoSFxfHxIkTeeSRR6hRQy9Ui1QGr32VwJ7T6QCE+rkxq29LgysSESl7JQp23t7eNsv/Ox7czQx3MmDAAFJTU5k2bRrJycm0adOGdevWWTtUJCYm4uBge2MxISGBTZs28c0331z1uMuXL8disTBo0KAr1jk7O7N8+XJefPFFcnNzqV+/PhMnTrR5705EKq5v96ew6KdjADg5OjB3cDs8nG9qdCcRkQrBZLFYLEYXURFlZGTg7e1Nenq6HsuKlCOnL16m91s/kn65aPilmfe3YGinUGOLEhG5CfZkjhv+FTY1NZWEhAQAmjRpQs2aNW/0UCIipSK/0Mz4Zdutoa5niyAevb2ewVWJiNw6dneeyMrK4rHHHqNWrVrceeed3HnnnQQHBzNy5Eiys7PLokYRkRL5+ze/WqcMq1PDldcean1DUx2KiFRUdge76OhoNm7cyBdffMHFixe5ePEin3/+ORs3buSZZ54pixpFRK5rQ8JZFmw8AkA1BxP/GNQWb1dNGSYiVYvd79j5+/vzySef0K1bN5v29evX8/DDD5Oamlqa9ZVbesdOpPxIycih11s/cj4rD4Ap9zZj1B0NrrOXiEjFYE/msPuOXXZ29hVTgAEEBAToUayI3HKFZgsTPtphDXU9mgYwsmt9g6sSETGG3cGuU6dOTJ8+nZycHGvb5cuXmTFjxnUHFRYRKW1vxx5i87HzANTyduGN/mF6r05Eqiy7e8XOmTOHnj17XjFAsYuLC19//XWpFygicjU/H07j7e8PAeDoYOLtQW2p4W7f1IYiIpWJ3cGuVatWHDp0iKVLl3Lw4EEABg0axJAhQ3B1dS31AkVEipN6KZenVuzk97eEo++5jQ6hvsYWJSJiMLuCXX5+Pk2bNuXLL79k9OjRZVWTiMg1FZotRH+8k9RLRXNW39HYnyfvamhwVSIixrPrHbvq1avbvFsnImKEt2IP8eOhNABqejoz++E2ODjovToREbs7T4wdO5bXXnuNgoKCsqhHROSaYg+k8HZs0Xt1DiZ4a2Abano6G1yViEj5YPc7dlu3biU2NpZvvvmGVq1a4e7ubrN+1apVpVaciMh/O3Eui4krdlqX/9qzKZ0b+htXkIhIOWN3sPPx8aFfv35lUYuIyFVdzitkzJLtZOQUPS2IahHIE3dqEGIRkf9md7BbvHhxWdQhInJVFouFFz7bw4GkDAAa+LtrvDoRkWKU+B07s9nMa6+9RpcuXejQoQOTJk3i8uXLZVmbiAgASzYnsmrHaQDcnBxZ8Gg4ni6aB1ZE5H+VONi9/PLLPP/883h4eFC7dm3eeustxo4dW5a1iYiwPfECM7/YZ11+rV9rbgv0NLAiEZHyq8TB7oMPPmD+/Pl8/fXXrF69mi+++IKlS5diNpvLsj4RqcLSMnP5vyXbyS8sGoV4ZNf69AkLNrgqEZHyq8TBLjExkd69e1uXIyMjMZlMnDlzpkwKE5GqraDQzPhlO0jOKBo7s2OoL5N6NTW4KhGR8q3Ewa6goAAXFxebturVq5Ofn1/qRYmI/O2bBOKOngMgwNOZuUPaUt3R7qE3RUSqlBL3irVYLAwfPhxn5z8GAs3JyWHMmDE2Y9lpHDsRuVlf7Uni3Y1HAajmYGLekHYEeLpcZy8RESlxsBs2bNgVbY888kipFiMicvhsJn/5ZLd1+YV7m9Eh1NfAikREKo4SBzuNXyciZS0zt4Anl8STmVs0CPF9YcEM7xxqbFEiIhWIXlgRkXKh0GzhqY92cOhsJgBNAj15tV8rDUIsImIHBTsRKRde//ogsQfPAuDlUo0Fj4bj5mT35DgiIlWagp2IGO6T+FPWzhKODibmDwmnvr/7dfYSEZH/pWAnIoaKP3Ge51ftsS6/2Kc5XRv7G1iRiEjFpWAnIoY5dSGbJz6MJ6+waAabR26vy6OdQo0tSkSkAlOwExFDZOUWMOr9baRl5gHQuaEf0/u0MLgqEZGKTcFORG45s9nCxBU7OZh8CYBQPzfmD2mnmSVERG6SfoqKyC33928T+GZ/CgCeLtX497AO+Lg5GVyViEjFp2AnIrfU6h2nmbf+CAAOJvjHoLY0CvAwuCoRkcpBwU5EbpkdiRf466d/TBc25d7mdGsSYGBFIiKVi4KdiNwSZy5e5vEP48krKOoBO7BDCCO6hBpblIhIJaNgJyJlLiu3gNEfbCP1Ui4AHev7MvP+lpouTESklCnYiUiZyi80M3bZdvadyQAgxNeVBY+E41RNP35EREqbfrKKSJmxWCw8v2oPGxJSgaIesAuHdcDXXT1gRUTKgoKdiJSZN7/9lZXxpwBwcnTgX0Pbc1ugp8FViYhUXgp2IlImlm4+wdvfHwbAZILZA8K4vYGfwVWJiFRu5SLYzZs3j9DQUFxcXIiIiGDLli1X3bZbt26YTKYrPvfee691m+HDh1+xvmfPnjbHOX/+PEOGDMHLywsfHx9GjhxJZmZmmV2jSFXy7f4Upq7ea12eem9z/tw62MCKRESqBsOD3YoVK4iOjmb69Ols376dsLAwoqKiOHv2bLHbr1q1iqSkJOtn7969ODo60r9/f5vtevbsabPdRx99ZLN+yJAh7Nu3j2+//ZYvv/ySH374gccff7zMrlOkqtieeIHxH23HbClafvzOBjzWtb6xRYmIVBEmi8ViMbKAiIgIOnTowNy5cwEwm82EhIQwfvx4Jk2adN3958yZw7Rp00hKSsLd3R0oumN38eJFVq9eXew+Bw4coHnz5mzdupX27dsDsG7dOnr37s2pU6cIDr7+nYWMjAy8vb1JT0/Hy8urhFcrUrkdTc2k3zs/cyE7H4D7woKZM6ANDg4a1kRE5EbZkzkMvWOXl5dHfHw8kZGR1jYHBwciIyOJi4sr0TEWLlzIwIEDraHudxs2bCAgIIAmTZrw5JNPcu7cOeu6uLg4fHx8rKEOIDIyEgcHBzZv3lzseXJzc8nIyLD5iMgfzl7KYdjiLdZQ17mhH3/r31qhTkTkFjI02KWlpVFYWEhgYKBNe2BgIMnJydfdf8uWLezdu5dRo0bZtPfs2ZMPPviA2NhYXnvtNTZu3EivXr0oLCwEIDk5mYAA22mMqlWrhq+v71XPGxMTg7e3t/UTEhJiz6WKVGqZuQU89t5WTp6/DEDTIE8WPBqOczVHgysTEalaqhldwM1YuHAhrVq1omPHjjbtAwcOtH7dqlUrWrduTcOGDdmwYQM9evS4oXNNnjyZ6Oho63JGRobCnQhFAxA/uSSevaeL7mLX9nHl/cc64uVS3eDKRESqHkPv2Pn7++Po6EhKSopNe0pKCkFBQdfcNysri+XLlzNy5MjrnqdBgwb4+/tz+HDR0AtBQUFXdM4oKCjg/PnzVz2vs7MzXl5eNh+Rqs5isfDcp7v58VAaAN6u1Xn/sQ4EerkYXJmISNVkaLBzcnIiPDyc2NhYa5vZbCY2NpZOnTpdc9+VK1eSm5vLI488ct3znDp1inPnzlGrVi0AOnXqxMWLF4mPj7du8/3332M2m4mIiLjBqxGpWiwWCzO+2M+q7acBcK7mwMJh7WkUoAGIRUSMYvhwJ9HR0fzrX//i/fff58CBAzz55JNkZWUxYsQIAIYOHcrkyZOv2G/hwoX07dsXPz/bAU8zMzP5y1/+wi+//MLx48eJjY3l/vvvp1GjRkRFRQHQrFkzevbsyejRo9myZQs//fQT48aNY+DAgSXqEStS1VksFl5dd5D3fj4OgIMJ3hrYlvahvsYWJiJSxRn+jt2AAQNITU1l2rRpJCcn06ZNG9atW2ftUJGYmIiDg23+TEhIYNOmTXzzzTdXHM/R0ZHdu3fz/vvvc/HiRYKDg/nTn/7ErFmzcHZ2tm63dOlSxo0bR48ePXBwcKBfv368/fbbZXuxIpXEnO8O8e7Go0DRrBJ/eyiMni2v/fqEiIiUPcPHsauoNI6dVFXvbDjCa+sOWpdfeaAVgyPqGliRiEjlVmHGsRORimXRpmM2oW56n+YKdSIi5YiCnYiUyLLNicz8cr91+bmeTRnRRVOFiYiUJwp2InJdn8af4oXVe6zLE3o05sluDQ2sSEREiqNgJyLX9MWuM/zlk138/jbuE3c2YGJkY2OLEhGRYinYichVfbMvmadX7MT8W6gb3jmUSb2aYjJp/lcRkfJIwU5EirUh4Szjlu2g8LdUN7BDCNP+3FyhTkSkHFOwE5ErbEg4yxMfxpNXaAbggba1efmBVjg4KNSJiJRnhg9QLCLly7q9SYz/aAf5hUV36nq3CuJvD7XGUaFORKTcU7ATEatV20/xl092Wx+/9m4VxJwBbanmqJv7IiIVgYKdiACw5JcTTFm917rcr10dXuvXSqFORKQCUbATEf75wxFeWfvHjBJDO9XjxT4t9E6diEgFo2AnUoVZLBbe/O4Qb8cesraNuashz/Vsot6vIiIVkIKdSBVlsVh4ac0BFm46Zm179k+3MbZ7I4U6EZEKSsFOpAoqNFuYsnoPH205aW2b9ufmPNZVc7+KiFRkCnYiVUx+oZlnV+7i851nADCZ4NUHWzGgQ12DKxMRkZulYCdSheTkFzLhox18sz8FgGoOJmYPaMN9YcEGVyYiIqVBwU6kijiflcfoD7YRf+ICAE6ODswb0o57mgcaXJmIiJQWBTuRKuBYWhYjFm/h+LlsAFyrO/Kvoe3p2tjf4MpERKQ0KdiJVHJbj59n9AfbuJidD0CApzOLhnegZW1vgysTEZHSpmAnUol9vvM0f1m5m7xCMwBNgzxZNLwDwT6uBlcmIiJlQcFOpBKyWCzMW3+YN7751dp2R2N/5g9ph6dLdQMrExGRsqRgJ1LJ5BeaeeGzPXy87ZS1bVDHEGbe35LqmvdVRKRSU7ATqUQycvL5vyXb2XQ4zdr2XM+mjLmrgWaTEBGpAhTsRCqJUxeyeey9rfyakgmAUzUHZj8cxp9ba4w6EZGqQsFOpBKIP3GeMUu2k3opF4AabtX597D2hNfzNbgyERG5lRTsRCowi8XCB3EnmPXlfgrMFgDq+7uzeHgHQv3dDa5ORERuNQU7kQoqO6+A51ftYfVvc74CdGrgx/wh7ajh7mRgZSIiYhQFO5EK6FhaFmM+jCch5ZK17Ym7GvCXPzWhmnq+iohUWQp2IhXMN/uSeebjXVzKLQDA3cmRN/qH0atVLYMrExERoynYiVQQhWYLs79NYN76I9a2RgEeLHgknEYBHgZWJiIi5YWCnUgFcD4rjwkf7bAZn+7e1rV4vV9r3J3111hERIroXwSRcm7nyYv835J4zqTnAODoYGJyr6aM7Fpfgw6LiIgNBTuRcspstrDop2O8vi6BvEIzAP4ezswb3JaIBn4GVyciIuWRgp1IOXTm4mWeXbmLn4+cs7aF16vB/CHtCPRyMbAyEREpzxTsRMqZ/+w6w5TP9pCRU9Tr1WSCUV3r85eopjhV01AmIiJydQp2IuVE+uV8pn2+l8//a8DhWt4u/P3hMDo39DewMhERqSgU7ETKgZ+PpPHsx7usHSQA7gsLZtb9LfF2q25gZSIiUpGUi+c68+bNIzQ0FBcXFyIiItiyZctVt+3WrRsmk+mKz7333gtAfn4+zz33HK1atcLd3Z3g4GCGDh3KmTNnbI4TGhp6xTFeffXVMr1Okf+VW1DIK2sPMOTfm62hztOlGm8NbMPbg9oq1ImIiF0Mv2O3YsUKoqOjWbBgAREREcyZM4eoqCgSEhIICAi4YvtVq1aRl5dnXT537hxhYWH0798fgOzsbLZv387UqVMJCwvjwoULPPXUU9x3331s27bN5lgzZ85k9OjR1mVPT88yukqRKx1MzuDp5Ts5mPzHtGCdGvjxxsNh1PZxNbAyERGpqAwPdrNnz2b06NGMGDECgAULFrBmzRoWLVrEpEmTrtje19fXZnn58uW4ublZg523tzfffvutzTZz586lY8eOJCYmUrduXWu7p6cnQUFBpX1JIteUW1DIuxuPMvf7w9ZhTJwcHfhLVBNGdq2Pg4PGphMRkRtj6KPYvLw84uPjiYyMtLY5ODgQGRlJXFxciY6xcOFCBg4ciLu7+1W3SU9Px2Qy4ePjY9P+6quv4ufnR9u2bfnb3/5GQUHBDV2HSEltPnqO3m/9yOxvf7WGuiaBnnw+rguj72ygUCciIjfF0Dt2aWlpFBYWEhgYaNMeGBjIwYMHr7v/li1b2Lt3LwsXLrzqNjk5OTz33HMMGjQILy8va/uECRNo164dvr6+/Pzzz0yePJmkpCRmz55d7HFyc3PJzc21LmdkZFy3PpHfXcjKI+arA3y87ZS1zdHBxKg76jMx8jZcqjsaWJ2IiFQWhj+KvRkLFy6kVatWdOzYsdj1+fn5PPzww1gsFt555x2bddHR0davW7dujZOTE0888QQxMTE4OztfcayYmBhmzJhRuhcglZ7FYuGzHad5ac0Bzmf98W5omxAfXnmgFc2Dva6xt4iIiH0MfRTr7++Po6MjKSkpNu0pKSnXffctKyuL5cuXM3LkyGLX/x7qTpw4wbfffmtzt644ERERFBQUcPz48WLXT548mfT0dOvn5MmT1zyeyLG0LIb8ezPRH++yhjpP52rMur8Fnz7ZWaFORERKnaF37JycnAgPDyc2Npa+ffsCYDabiY2NZdy4cdfcd+XKleTm5vLII49cse73UHfo0CHWr1+Pn9/159XcuXMnDg4OxfbEBXB2di72Tp7I/7J2jlh/mLwCs7X93la1mNanuaYEExGRMmP4o9jo6GiGDRtG+/bt6dixI3PmzCErK8vaS3bo0KHUrl2bmJgYm/0WLlxI3759rwht+fn5PPTQQ2zfvp0vv/ySwsJCkpOTgaIetU5OTsTFxbF582a6d++Op6cncXFxTJw4kUceeYQaNWrcmguXSmlDwllmfbmfI6lZ1rbaPq7M6tuCu5sGXmNPERGRm2d4sBswYACpqalMmzaN5ORk2rRpw7p166wdKhITE3FwsH1inJCQwKZNm/jmm2+uON7p06f5z3/+A0CbNm1s1q1fv55u3brh7OzM8uXLefHFF8nNzaV+/fpMnDjR5r07EXscSMrglbUH+PFQmrXN0cHEyK71eTqyMW5Ohv9VExGRKsBksVgsRhdREWVkZODt7U16evp139+TyislI4e/f5PAyvhT/PffpDYhPrz8QEtaBHsbV5yIiFQK9mQO3UYQuQFZuQW8+8NR/vXDUS7nF1rba/u48lyvpvy5VS2NSSciIrecgp2IHQrNFj7edpLZ3/5K6qU/xjX0dKnGuO6NGNY5VGPSiYiIYRTsRErAYrGw8ddUYtYeJCHlj7ldqzmYeOT2ekzo0RhfdycDKxQREVGwE7kmi8XCj4fSeDv2ENtOXLBZ17NFEM/1akp9/6tPZyciInIrKdiJFMNisbA+4SxvxR5m18mLNuvC6njzwr3N6Vjf15jiRERErkLBTuS/mM0Wvj2Qwj++P8Te07bzATcK8OCpHo25Vx0jRESknFKwE6Eo0K3bl8zbsYc4mHzJZl3TIE/G392YXi2DFOhERKRcU7CTKq2g0MyaPUnM/f4wh85m2qxrEezFhB6NuadZoAKdiIhUCAp2UiVdzM5j+daTfBh3gtMXL9usCwvx4akejejeJACTSYFOREQqDgU7qVJ+TbnE4p+O89mOU+Tkm23WhderwYQejbmzsb8CnYiIVEgKdlLpmc1FPVwX/3ScTYfTrlh/d9MARnWtT6eGfgp0IiJSoSnYSaV1KSefldtO8X7ccU6cy7ZZ5+7kSP/2IQzrHKpx6EREpNJQsJNKxWKxsD3xIp/En+SLXUlk5hbYrK/n58awTqH0b18HT5fqBlUpIiJSNhTspFJIychh1fbTfBJ/kiOpWVes79rInxFdQunWJABH9XAVEZFKSsFOKqy8AjOxB1L4eNtJNv6aitliu97dyZH72tRmRJdQbgv0NKZIERGRW0jBTioUi8XC/qQMVm47xec7T3MhO/+KbSLq+9K/fQi9WwXh5qT/xUVEpOrQv3pS7lksFhJSLrF2dxJr9iQV+6g12NuFh8Lr0C+8DvX81BlCRESqJgU7KZcsFgsHky+xdk9RmDtaTJhzruZAVIsg+revQ+eG/np3TkREqjwFOyk3fg9za3YnsXZPEkfTrgxzJhN0qOfLfW2C6RMWjLereraKiIj8TsFODJVXYGbbifOsP3iW2ANnrx7mQn25t1UterYMItDLxYBKRUREyj8FO7nlUjJy2JBwlvUHU9l0OO2KseagKMx1DPXl3ta16NkiiACFORERketSsJMyV2i2sPPkBdYfTGV9wln2nckodjuH3+7M/bl1LaJaBhHgqTAnIiJiDwU7KXUWi4VDZzP55eg54o6cI+7oOS4WMywJQA236nRrEkC3JjW5s3FNarg73eJqRUREKg8FO7lpFouFI6lZxB09xy9Hz7H56DnSMvOuun3L2l7c3SSAbk0DCKvjo96sIiIipUTBTuxmNls4nJrJtuMXrGEu9VLuVbf3dKlG10b+dG8aQLfbaup9ORERkTKiYCfXdSErj50nL7I98QI7Ei+y6+RFLhXT4eF3Hs7V6Fjfl04N/OjU0I9mtbx0V05EROQWULATG3kFZn5NucSOkxfZceICO05e5FgxQ5D8N3cnRzrU9+X2Bn50auBHi2Avqjk63KKKRURE5HcKdlVYZm4BB5Iy2H8mg31n0tl3JoNDKZnkFZqvuV+ApzPt6tagTV0fOtb3pVVtb6oryImIiBhOwa4KsFgspGTkcjA5g/1JGew7UxTmjp/LwmK59r5Ojg60rO1F27o1aFvXh7Z1axDs7YLJpEerIiIi5Y2CXSVisVg4k57DoZRLHD6bya8plzh0NpPDKZnXfCfudw4maFDTg+a1vGgT4kPbuj40D/bCuZrjLaheREREbpaCXQWUlVvA8XNZnDiXzbG0LI6lZf0W4C6RlVdYomM4V3OgaZAnzYO9aRHsRfNgL5oFeeHqpBAnIiJSUSnYlVOZuQUcTysKb8fPZXE8Lavov+eyrzm0SHFq+7hyW6AHjQM9aVbLkxbB3jTwd1cHBxERkUpGwa4cOnUhm66vrbd7vxBfV24L8KRRoAeNAzy5LdCDhjU9cHfWt1lERKQq0L/45VCQlwvVHU3kF17Zs8Hfw5n6/m7U83Onvr879fzcCPVzp0FNd9yc9O0UERGpypQEyqFqjg70alkL52oOhPq7E+r3W4Dzd8dDd99ERETkKpQSyqm3B7U1ugQRERGpYPT2vIiIiEgloWAnIiIiUkmUi2A3b948QkNDcXFxISIigi1btlx1227dumEyma743HvvvdZtLBYL06ZNo1atWri6uhIZGcmhQ4dsjnP+/HmGDBmCl5cXPj4+jBw5kszMzDK7RhEREZGyZniwW7FiBdHR0UyfPp3t27cTFhZGVFQUZ8+eLXb7VatWkZSUZP3s3bsXR0dH+vfvb93m9ddf5+2332bBggVs3rwZd3d3oqKiyMnJsW4zZMgQ9u3bx7fffsuXX37JDz/8wOOPP17m1ysiIiJSVkwWy/VmCy1bERERdOjQgblz5wJgNpsJCQlh/PjxTJo06br7z5kzh2nTppGUlIS7uzsWi4Xg4GCeeeYZnn32WQDS09MJDAzkvffeY+DAgRw4cIDmzZuzdetW2rdvD8C6devo3bs3p06dIjg4+LrnzcjIwNvbm/T0dLy8vG7iT0BERETk6uzJHIbescvLyyM+Pp7IyEhrm4ODA5GRkcTFxZXoGAsXLmTgwIG4u7sDcOzYMZKTk22O6e3tTUREhPWYcXFx+Pj4WEMdQGRkJA4ODmzevLnY8+Tm5pKRkWHzERERESlPDA12aWlpFBYWEhgYaNMeGBhIcnLydfffsmULe/fuZdSoUda23/e71jGTk5MJCAiwWV+tWjV8fX2vet6YmBi8vb2tn5CQkOtfoIiIiMgtZPg7djdj4cKFtGrVio4dO5b5uSZPnkx6err1c/LkyTI/p4iIiIg9DA12/v7+ODo6kpKSYtOekpJCUFDQNffNyspi+fLljBw50qb99/2udcygoKArOmcUFBRw/vz5q57X2dkZLy8vm4+IiIhIeWJosHNyciI8PJzY2Fhrm9lsJjY2lk6dOl1z35UrV5Kbm8sjjzxi016/fn2CgoJsjpmRkcHmzZutx+zUqRMXL14kPj7eus3333+P2WwmIiKiNC5NRERE5JYzfEqx6Ohohg0bRvv27enYsSNz5swhKyuLESNGADB06FBq165NTEyMzX4LFy6kb9+++Pn52bSbTCaefvppXnrpJRo3bkz9+vWZOnUqwcHB9O3bF4BmzZrRs2dPRo8ezYIFC8jPz2fcuHEMHDiwRD1iRURERMojw4PdgAEDSE1NZdq0aSQnJ9OmTRvWrVtn7fyQmJiIg4PtjcWEhAQ2bdrEN998U+wx//rXv5KVlcXjjz/OxYsX6dq1K+vWrcPFxcW6zdKlSxk3bhw9evTAwcGBfv368fbbb5fdhYqIiIiUMcPHsauoNI6diIiI3AoVZhw7ERERESk9CnYiIiIilYTh79hVVL8/wdYMFCIiIlKWfs8aJXl7TsHuBl26dAlAM1CIiIjILXHp0iW8vb2vuY06T9wgs9nMmTNn8PT0xGQylfrxMzIyCAkJ4eTJk+qcYTB9L8oHfR/KD30vygd9H8qHW/F9sFgsXLp0ieDg4CtGCvlfumN3gxwcHKhTp06Zn0ezXJQf+l6UD/o+lB/6XpQP+j6UD2X9fbjenbrfqfOEiIiISCWhYCciIiJSSSjYlVPOzs5Mnz4dZ2dno0up8vS9KB/0fSg/9L0oH/R9KB/K2/dBnSdEREREKgndsRMRERGpJBTsRERERCoJBTsRERGRSkLBrpyaN28eoaGhuLi4EBERwZYtW4wuqcr54Ycf6NOnD8HBwZhMJlavXm10SVVSTEwMHTp0wNPTk4CAAPr27UtCQoLRZVU577zzDq1bt7aO1dWpUye++uoro8uq8l599VVMJhNPP/200aVUOS+++CImk8nm07RpU6PLUrArj1asWEF0dDTTp09n+/bthIWFERUVxdmzZ40urUrJysoiLCyMefPmGV1KlbZx40bGjh3LL7/8wrfffkt+fj5/+tOfyMrKMrq0KqVOnTq8+uqrxMfHs23bNu6++27uv/9+9u3bZ3RpVdbWrVt59913ad26tdGlVFktWrQgKSnJ+tm0aZPRJalXbHkUERFBhw4dmDt3LlA0fVlISAjjx49n0qRJBldXNZlMJj777DP69u1rdClVXmpqKgEBAWzcuJE777zT6HKqNF9fX/72t78xcuRIo0upcjIzM2nXrh3z58/npZdeok2bNsyZM8fosqqUF198kdWrV7Nz506jS7GhO3blTF5eHvHx8URGRlrbHBwciIyMJC4uzsDKRMqH9PR0oChUiDEKCwtZvnw5WVlZdOrUyehyqqSxY8dy77332vxbIbfeoUOHCA4OpkGDBgwZMoTExESjS9JcseVNWloahYWFBAYG2rQHBgZy8OBBg6oSKR/MZjNPP/00Xbp0oWXLlkaXU+Xs2bOHTp06kZOTg4eHB5999hnNmzc3uqwqZ/ny5Wzfvp2tW7caXUqVFhERwXvvvUeTJk1ISkpixowZ3HHHHezduxdPT0/D6lKwE5EKY+zYsezdu7dcvMdSFTVp0oSdO3eSnp7OJ598wrBhw9i4caPC3S108uRJnnrqKb799ltcXFyMLqdK69Wrl/Xr1q1bExERQb169fj4448NfT1Bwa6c8ff3x9HRkZSUFJv2lJQUgoKCDKpKxHjjxo3jyy+/5IcffqBOnTpGl1MlOTk50ahRIwDCw8PZunUrb731Fu+++67BlVUd8fHxnD17lnbt2lnbCgsL+eGHH5g7dy65ubk4OjoaWGHV5ePjw2233cbhw4cNrUPv2JUzTk5OhIeHExsba20zm83ExsbqXRapkiwWC+PGjeOzzz7j+++/p379+kaXJL8xm83k5uYaXUaV0qNHD/bs2cPOnTutn/bt2zNkyBB27typUGegzMxMjhw5Qq1atQytQ3fsyqHo6GiGDRtG+/bt6dixI3PmzCErK4sRI0YYXVqVkpmZafOb17Fjx9i5cye+vr7UrVvXwMqqlrFjx7Js2TI+//xzPD09SU5OBsDb2xtXV1eDq6s6Jk+eTK9evahbty6XLl1i2bJlbNiwga+//tro0qoUT0/PK94vdXd3x8/PT++d3mLPPvssffr0oV69epw5c4bp06fj6OjIoEGDDK1Lwa4cGjBgAKmpqUybNo3k5GTatGnDunXrruhQIWVr27ZtdO/e3bocHR0NwLBhw3jvvfcMqqrqeeeddwDo1q2bTfvixYsZPnz4rS+oijp79ixDhw4lKSkJb29vWrduzddff80999xjdGkihjh16hSDBg3i3Llz1KxZk65du/LLL79Qs2ZNQ+vSOHYiIiIilYTesRMRERGpJBTsRERERCoJBTsRERGRSkLBTkRERKSSULATERERqSQU7EREREQqCQU7ERERkUpCwU5ERESkklCwExEREakkFOxEREooNTWVJ598krp16+Ls7ExQUBBRUVH89NNPRpcmIgJorlgRkRLr168feXl5vP/++zRo0ICUlBRiY2M5d+5cmZwvLy8PJyenMjm2iFROumMnIlICFy9e5Mcff+S1116je/fu1KtXj44dOzJ58mTuu+8+6zZPPPEEgYGBuLi40LJlS7788kvrMT799FNatGiBs7MzoaGh/P3vf7c5R2hoKLNmzWLo0KF4eXnx+OOPA7Bp0ybuuOMOXF1dCQkJYcKECWRlZd26ixeRCkPBTkSkBDw8PPDw8GD16tXk5uZesd5sNtOrVy9++uknlixZwv79+3n11VdxdHQEID4+nocffpiBAweyZ88eXnzxRaZOncp7771nc5w33niDsLAwduzYwdSpUzly5Ag9e/akX79+7N69mxUrVrBp0ybGjRt3Ky5bRCoYk8VisRhdhIhIRfDpp58yevRoLl++TLt27bjrrrsYOHAgrVu35ptvvqFXr14cOHCA22677Yp9hwwZQmpqKt9884217a9//Str1qxh3759QNEdu7Zt2/LZZ59Ztxk1ahSOjo68++671rZNmzZx1113kZWVhYuLSxlesYhUNLpjJyJSQv369ePMmTP85z//oWfPnmzYsIF27drx3nvvsXPnTurUqVNsqAM4cOAAXbp0sWnr0qULhw4dorCw0NrWvn17m2127drFe++9Z71j6OHhQVRUFGazmWPHjpX+RYpIhabOEyIidnBxceGee+7hnnvuYerUqYwaNYrp06fz7LPPlsrx3d3dbZYzMzN54oknmDBhwhXb1q1bt1TOKSKVh4KdiMhNaN68OatXr6Z169acOnWKX3/9tdi7ds2aNbtiWJSffvqJ2267zfoeXnHatWvH/v37adSoUanXLiKVjx7FioiUwLlz57j77rtZsmQJu3fv5tixY6xcuZLXX3+d+++/n7vuuos777yTfv368e2333Ls2DG++uor1q1bB8AzzzxDbGwss2bN4tdff+X9999n7ty5173T99xzz/Hzzz8zbtw4du7cyaFDh/j888/VeUJEiqU7diIiJeDh4UFERARvvvkmR44cIT8/n5CQEEaPHs3zzz8PFHWuePbZZxk0aBBZWVk0atSIV199FSi68/bxxx8zbdo0Zs2aRa1atZg5cybDhw+/5nlbt27Nxo0beeGFF7jjjjuwWCw0bNiQAQMGlPUli0gFpF6xIiIiIpWEHsWKiIiIVBIKdiIiIiKVhIKdiIiISCWhYCciIiJSSSjYiYiIiFQSCnYiIiIilYSCnYiIiEgloWAnIiIiUkko2ImIiIhUEgp2IiIiIpWEgp2IiIhIJaFgJyIiIlJJ/D9Gqoax09EF2gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "survive = 0.5\n",
        "scores = np.linspace(0, 5)\n",
        "probs = prob_survive(scores)\n",
        "plt.plot(scores, probs)\n",
        "decorate(xlabel='Score', ylabel='Probability of survival')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2HcXMBexAY1"
      },
      "source": [
        "### The simulator\n",
        "\n",
        "The biggest change in the simulator is in `step`, which runs `melee` to determine the fitness of each agent, and `prob_survive` to map from fitness to probability of surviving.\n",
        "\n",
        "\n",
        "This code is made up of a mixture of O(n) code to create agents and steps for the simulator and O(1) code to run the simulation.\n",
        "\n",
        "*See comment below each method for found complexity*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hH68jE1dxAY1"
      },
      "outputs": [],
      "source": [
        "class PDSimulation(Simulation):\n",
        "\n",
        "    def __init__(self, tournament, agents):\n",
        "        \"\"\"Create the simulation:\n",
        "\n",
        "        tournament: Tournament object\n",
        "        agents: sequence of agents\n",
        "        \"\"\"\n",
        "        self.tournament = tournament\n",
        "        self.agents = np.asarray(agents)\n",
        "        self.instruments = []\n",
        "\n",
        "        #Complexity O(1)\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\"Simulate a time step and update the instruments.\n",
        "        \"\"\"\n",
        "        self.tournament.melee(self.agents)\n",
        "        Simulation.step(self)\n",
        "\n",
        "        #Complexity O(1)\n",
        "\n",
        "    def choose_dead(self, fits):\n",
        "        \"\"\"Choose which agents die in the next timestep.\n",
        "\n",
        "        fits: fitness of each agent\n",
        "\n",
        "        returns: indices of the chosen ones\n",
        "        \"\"\"\n",
        "        ps = prob_survive(fits)\n",
        "        n = len(self.agents)\n",
        "        is_dead = np.random.random(n) < ps\n",
        "        index_dead = np.nonzero(is_dead)[0]\n",
        "        return index_dead\n",
        "\n",
        "        #Complexity O(n) where n is an array containing the fitness of each agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrEdPRWSxAY1"
      },
      "source": [
        "We might want to start with random agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "edJsxNyKxAY1"
      },
      "outputs": [],
      "source": [
        "def make_random_agents(n):\n",
        "    \"\"\"Make agents with random genotype.\n",
        "\n",
        "    n: number of agents\n",
        "\n",
        "    returns: sequence of agents\n",
        "    \"\"\"\n",
        "    agents = [Agent(np.random.choice(['C', 'D'], size=7))\n",
        "              for _ in range(n)]\n",
        "    return agents\n",
        "\n",
        "    #Complexity O(n) where n is the number of agents we would like to create"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xiu5icRxAY1"
      },
      "source": [
        "Or with all identical agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vpChOw8kxAY1"
      },
      "outputs": [],
      "source": [
        "def make_identical_agents(n, values):\n",
        "    \"\"\"Make agents with the given genotype.\n",
        "\n",
        "    n: number of agents\n",
        "    values: sequence of 'C' and 'D'\n",
        "\n",
        "    returns: sequence of agents\n",
        "    \"\"\"\n",
        "    agents = [Agent(values) for _ in range(n)]\n",
        "    return agents\n",
        "\n",
        "    #Complexity O(n) where n is the number of agents we would like to create"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrstqzt-xAY1"
      },
      "source": [
        "Here are the instruments to compute various metrics.\n",
        "\n",
        "`Niceness` is the average number of `C` across the genotypes in the population."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9gt7l7QVxAY9"
      },
      "outputs": [],
      "source": [
        "class Niceness(Instrument):\n",
        "    \"\"\"Fraction of cooperation in all genotypes.\"\"\"\n",
        "    label = 'Niceness'\n",
        "\n",
        "    def update(self, sim):\n",
        "        responses = np.array([agent.values for agent in sim.agents])\n",
        "        metric = np.mean(responses == 'C')\n",
        "        self.metrics.append(metric)\n",
        "    #Complexity O(n) where n is the number of agents we have to run through to get our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5jFHXb3xAY9"
      },
      "source": [
        "`Opening` is the fraction of agents that cooperate in the first round."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4ddL25J8xAY9"
      },
      "outputs": [],
      "source": [
        "class Opening(Instrument):\n",
        "    \"\"\"Fraction of agents that cooperate on the first round.\"\"\"\n",
        "    label = 'Opening'\n",
        "\n",
        "    def update(self, sim):\n",
        "        responses = np.array([agent.values[0] for agent in sim.agents])\n",
        "        metric = np.mean(responses == 'C')\n",
        "        self.metrics.append(metric)\n",
        "    #Complexity O(n) where n is the number of agents we have to run through to get our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K_1cyUaxAY9"
      },
      "source": [
        "`Retaliating` is the difference between (1) the fraction of agents that defect after the opponent defects and (2) the fraction of agents that defect after the opponent cooperates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "siFCZ78lxAY9"
      },
      "outputs": [],
      "source": [
        "class Retaliating(Instrument):\n",
        "    \"\"\"Tendency to defect after opponent defects.\"\"\"\n",
        "    label = 'Retaliating'\n",
        "\n",
        "    def update(self, sim):\n",
        "        after_d = np.array([agent.values[2::2] for agent in sim.agents])\n",
        "        after_c = np.array([agent.values[1::2] for agent in sim.agents])\n",
        "        metric = np.mean(after_d == 'D') - np.mean(after_c == 'D')\n",
        "        self.metrics.append(metric)\n",
        "    #Complexity O(n) where n is the number of agents we have to run through to get our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnGvoteuxAY-"
      },
      "source": [
        "Forgiving is the difference between the number of agents that cooperate after DC minus the number that cooperate after CD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iEaAAPNCxAY-"
      },
      "outputs": [],
      "source": [
        "class Forgiving(Instrument):\n",
        "    \"\"\"Tendency to cooperate if opponent cooperates after defecting.\"\"\"\n",
        "    label = 'Forgiving'\n",
        "\n",
        "    def update(self, sim):\n",
        "        after_dc = np.array([agent.values[5] for agent in sim.agents])\n",
        "        after_cd = np.array([agent.values[4] for agent in sim.agents])\n",
        "        metric = np.mean(after_dc == 'C') - np.mean(after_cd == 'C')\n",
        "        self.metrics.append(metric)\n",
        "    #Complexity O(n) where n is the number of agents we have to run through to get our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-7SsKptxAY-"
      },
      "source": [
        "Here's another metric intended to measure forgiveness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "O8TVIB8CxAY-"
      },
      "outputs": [],
      "source": [
        "class Forgiving2(Instrument):\n",
        "    \"\"\"Ability to cooperate after the first two rounds.\"\"\"\n",
        "    label = 'Forgiving2'\n",
        "\n",
        "    def update(self, sim):\n",
        "        after_two = np.array([agent.values[3:] for agent in sim.agents])\n",
        "        metric = np.mean(np.any(after_two=='C', axis=1))\n",
        "        self.metrics.append(metric)\n",
        "    #Complexity O(n) where n is the number of agents we have to run through to get our data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot results is used to show the results overtime for the steps in the simulation"
      ],
      "metadata": {
        "id": "agfMsi5fXx6s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9YSJc-g-xAY-"
      },
      "outputs": [],
      "source": [
        "def plot_result(index, **options):\n",
        "    \"\"\"Plots the results of the indicated instrument.\n",
        "\n",
        "    index: integer\n",
        "    \"\"\"\n",
        "    sim.plot(index, **options)\n",
        "    instrument = sim.instruments[index]\n",
        "    print(np.mean(instrument.metrics[1000:]))\n",
        "    decorate(xlabel='Time steps',\n",
        "                     ylabel=instrument.label)\n",
        "    #Complexity O(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre Designed Simulation\n",
        "To help explain how the tournament simulation works we created one that runs a tournament of only our backstabbing agent to see what happens with that. To start below we define a tournament with 100 agents, 2500 steps evolution steps, and our backstabbing agent. We also run it with a specific seed to get the same results each time (for demonstration purposes).\n",
        "\n",
        "This section contains no complexity analysis as it calls classes and functions to make up where is needed."
      ],
      "metadata": {
        "id": "Oo2QfwSxaK23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tour = Tournament()\n",
        "\n",
        "# User Input\n",
        "number = 100\n",
        "steps = 2500\n",
        "\n",
        "#Makes Agents\n",
        "agents = make_identical_agents(number, list('CDCDCDC'))\n",
        "\n",
        "#Starts Simulation\n",
        "sim = PDSimulation(tour, agents)\n",
        "\n",
        "#Adds Trackers\n",
        "sim.add_instrument(MeanFitness())\n",
        "sim.add_instrument(Niceness())\n",
        "sim.add_instrument(Opening())\n",
        "sim.add_instrument(Retaliating())\n",
        "sim.add_instrument(Forgiving())"
      ],
      "metadata": {
        "id": "xZcxVNARFufa",
        "outputId": "a02804ff-9770-494c-c705-ce759e05e60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'agent' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-fca6056d1f63>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Makes Agents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"random\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mmake_random_agents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Runs simulations with a seed\n",
        "np.random.seed(17)\n",
        "sim.run(steps)"
      ],
      "metadata": {
        "id": "CxzRAvi3GCRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graph below shows that, while at the start our mean score was low, and for a bit it plummited to nearly 1 score per agent, eventually the score ended up around 2.5"
      ],
      "metadata": {
        "id": "aS5BUp_VfZdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Displays Mean Fitness\n",
        "plot_result(0, color='C0')\n",
        "plt.show('figs/chap12-1')"
      ],
      "metadata": {
        "id": "WwMK6CrbHhH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Graph below here shows that the niceness of the agents as constantly fluctuating in a small range but most agents ended up being relatively nice."
      ],
      "metadata": {
        "id": "JRUWxewwhWCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Shows Niceness (Average number of Cooperators across all agents)\n",
        "plot_result(1, color='C1')"
      ],
      "metadata": {
        "id": "btjNZEZpHjoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graph below here shows that all of our agents started by cooperating at first (which was known) but eventually moved to being mostly but not entirely made up of agents who cooperated at first."
      ],
      "metadata": {
        "id": "dljtpumDhlqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Shows Opening (Agents who started with cooperation)\n",
        "plot_result(2, color='C2')"
      ],
      "metadata": {
        "id": "s6vYZRkyHsgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graph below shows that, despite not starting with any retaliation, the agents eventually began to be made up of equally as many agents who retaliated as thos who didn't."
      ],
      "metadata": {
        "id": "KIiwq_B9iLSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Shows Retaliation (Difference between agents who defect after defection and cooperate after defection)\n",
        "plot_result(3, color='C3')"
      ],
      "metadata": {
        "id": "xRkL6xYCHv8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At first none of our agents were considered forgiving, yet over time this too moved toward ab equalibrium of forgiving agents and unforgiving ones."
      ],
      "metadata": {
        "id": "UnNTNkZ6iZ3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Shows average amount of agents who forgive a round or two after defection\n",
        "plot_result(4, color='C4')"
      ],
      "metadata": {
        "id": "ulbkIyQvH0Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And last but not least, this shows that our agents ended up as mostly fully cooperative agents with minor tweaks. Our top three were one that retaliates only after memory has been fully established. One That defects at the start and one that backstabs the opponent if they cooperated at the start."
      ],
      "metadata": {
        "id": "Sh3V9EMhio5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import Series\n",
        "\n",
        "responses = [''.join(agent.values) for agent in sim.agents]\n",
        "Series(responses).value_counts()"
      ],
      "metadata": {
        "id": "KeBoho9gJfJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All in all this shows us that over time in a group of agents who begin by always betraying each other they will end up mostly cooperating, only having slight backstabbing tendencies that optimize the points. (See our second most poulated group which takes advantage of the openness of other agents.)"
      ],
      "metadata": {
        "id": "0eqHyn0DjRRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Round Robin Playoffs (ADDED)\n",
        "\n",
        "This is a mixture of code already seen and new code for a round robin tournament with a time complexity of O($n^{2}$).\n",
        "\n",
        "*See comment below each method to for found complexity.*"
      ],
      "metadata": {
        "id": "o3Ez5lgOqupo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PairwiseRoundRobinTournament:\n",
        "    def __init__(self, payoffs, num_rounds=6):\n",
        "        \"\"\"\n",
        "        Initialize the Pairwise Round-Robin Tournament.\n",
        "        payoffs: dict\n",
        "            Payoff matrix for the Prisoner's Dilemma.\n",
        "        num_rounds: int\n",
        "            Number of rounds for each pair.\n",
        "        \"\"\"\n",
        "        self.payoffs = payoffs\n",
        "        self.num_rounds = num_rounds\n",
        "\n",
        "        #Complexity O(1)\n",
        "\n",
        "    def play(self, agent1, agent2):\n",
        "        \"\"\"\n",
        "        Play a sequence of iterated Prisoner's Dilemma rounds between two agents.\n",
        "        agent1, agent2: Agent objects\n",
        "        Returns:\n",
        "            Tuple of scores (agent1_score, agent2_score).\n",
        "        \"\"\"\n",
        "        agent1.reset()\n",
        "        agent2.reset()\n",
        "        for _ in range(self.num_rounds):\n",
        "            resp1 = agent1.respond(agent2)\n",
        "            resp2 = agent2.respond(agent1)\n",
        "            pay1, pay2 = self.payoffs[resp1, resp2]\n",
        "            agent1.append(resp1, pay1)\n",
        "            agent2.append(resp2, pay2)\n",
        "        return agent1.score, agent2.score\n",
        "        #Complexity O(n) where n is the number of rounds in the tournament\n",
        "\n",
        "    def round_robin(self, agents):\n",
        "        \"\"\"\n",
        "        Conduct a full pairwise round-robin tournament.\n",
        "        agents: list of Agent objects\n",
        "        Updates agents' fitness values based on their average scores.\n",
        "        \"\"\"\n",
        "        n = len(agents)\n",
        "        totals = np.zeros(n)\n",
        "        for i in range(n):\n",
        "            for j in range(i, n):\n",
        "                print(f\"Agent {i} ({agents[i].values}) vs Agent {j} ({agents[j].values})\")\n",
        "                score1, score2 = self.play(agents[i], agents[j])\n",
        "                totals[i] += score1\n",
        "                totals[j] += score2\n",
        "        for i in range(n):\n",
        "            agents[i].fitness = totals[i] / (n - 1) / self.num_rounds   # Average score per agent\n",
        "\n",
        "        #Complexity O(n^2) since each agent plays each other agent and itself in this code."
      ],
      "metadata": {
        "id": "FoSqqfseq3NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PDSimulationWithRoundRobin(PDSimulation):\n",
        "    def __init__(self, tournament, agents):\n",
        "        super().__init__(tournament, agents)\n",
        "        #Complexity O(1)\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\"\n",
        "        Run one step of the simulation.\n",
        "        \"\"\"\n",
        "        # Run the full pairwise round-robin tournament\n",
        "        self.tournament.round_robin(self.agents)\n",
        "        Simulation.step(self)\n",
        "        #Complexity O(1)"
      ],
      "metadata": {
        "id": "q9Or1Ba-q6J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "payoffs = {('C', 'C'): (3, 3),\n",
        "           ('C', 'D'): (0, 5),\n",
        "           ('D', 'C'): (5, 0),\n",
        "           ('D', 'D'): (1, 1)}\n",
        "tour = PairwiseRoundRobinTournament(payoffs)\n",
        "tour.play(all_d, all_c)"
      ],
      "metadata": {
        "id": "ZVcHCvusrDHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agents = [all_c, all_d, tft, back, nf, StartDef]\n",
        "\n",
        "tour.round_robin(agents)"
      ],
      "metadata": {
        "id": "fy__TVbFrO_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for agent in agents:\n",
        "  print(agent.values, agent.fitness)"
      ],
      "metadata": {
        "id": "_PgUwtkOr1hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion/Discussion\n",
        "The Prisoner’s Dilemma is a widely studied framework for understanding behaviors like cooperation and competition (Vinney, 2024). It has real-world applications in psycology, economics, and bussines (Picardo, 2024). Simulations like ours offer a way to explore how different strategies evolve and adapt over time, providing insights into important questions: Why do people cooperate? How do competitive behaviors emerge? What makes a strategy successful in different environments?\n",
        "\n",
        "Our work showed that individual choices can have a big impact on group outcomes. This is important for understanding systems like social cooperation, resource-sharing, and even strategic decision-making in competitive scenarios.\n",
        "This project explored simulations of the Prisoner's Dilemma to study how different strategies interact and evolve over time. By implementing various agent behaviors, including Always Cooperate, Always Defect, Tit-for-Tat, and new strategies like Backstabbing, No Forgiveness, and Start Defection, we gained insight into how these strategies compete and adapt in a population. Enhancements such as the Round-Robin Tournament method allowed us to analyze these interactions more thoroughly and eliminate biases that existed in the original Melee Tournament setup.\n",
        "\n",
        "The Round-Robin Tournament was a key improvement because it ensured every agent interacted with every other agent in the population. This provided a fair evaluation of strategy performance by comparing each strategy’s effectiveness against the entire group. In contrast, the Melee Tournament only considered a limited number of interactions, which could skew results based on random pairings. The results from these simulations showed that balanced strategies like Tit-for-Tat tend to perform well in cooperative environments, while exploitative strategies like Backstabbing thrive only under specific conditions.\n",
        "While this project explored important ideas, there are several directions we could take to expand this work:\n",
        "\n",
        "* Memory-Size-Three Agents: Future work could involve agents that base their decisions on longer histories. This would allow for more complex strategies that detect patterns in opponent behavior over time. Adding this feature would require storing more data for each agent and adjusting their decision-making process. Specifically adding one more turn of memory would require each agent to expand to a string of 16 characters instead of 7. This is because storing three turns of memory when each have 2 choices mean the options for possible three turns is $3^{2} = 9$\n",
        "\n",
        "* New Interactions: Adding more genomes and agent types would provide a richer set of interactions and provide insights into the performance of strategies in varied competitive settings. This would make the simulation not only more comprehensive but also more reflective of real-world complexities. Another option for a new interaction would be adding a number that randomly decides what the response is.\n",
        "\n",
        "* Real-World Applications: Applying the simulation to real-world data, like social networks, could show how these principles work in actual systems and help us make predictions.\n",
        "\n",
        "This project demonstrated the power of simulations for studying strategic interactions in populations. By adding features like the Round-Robin Tournament and memory-based strategies, we deepened our understanding of how cooperation and competition evolve. Expanding this work to include more complex strategies, dynamic environments, or real-world applications could uncover even more insights into the factors that shape behaviors in populations. These findings have practical importance, offering lessons for understanding cooperation and competition in a wide range of systems, from ecosystems to human societies.\n",
        "\n",
        "Below you can find a segment of code that will let you execute a Prisoner's Dilemma problem with your own step length, agent, and number of agents.\n"
      ],
      "metadata": {
        "id": "EqZ5igGuJgDO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kodWVGrzxAY-"
      },
      "source": [
        "## Inputable Code\n",
        "\n",
        "Here's a simulation that runs a chosen amount of a chosen agent (or random).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9DdRc9CxAY-"
      },
      "outputs": [],
      "source": [
        "tour = Tournament()\n",
        "\n",
        "# User Input\n",
        "agent = input(\"Input your 7 letter character string or 'random' for a random group:\")\n",
        "number = int(input(\"Input your number of agents:\"))\n",
        "steps = int(input(\"Enter the number of steps you want the sim to run for:\"))\n",
        "\n",
        "#Makes Agents\n",
        "if agent == \"random\":\n",
        "  agents = make_random_agents(number)\n",
        "else:\n",
        "  agents = make_identical_agents(number, list(agent))\n",
        "\n",
        "#Starts Simulation\n",
        "sim = PDSimulation(tour, agents)\n",
        "\n",
        "#Adds Trackers\n",
        "sim.add_instrument(MeanFitness())\n",
        "sim.add_instrument(Niceness())\n",
        "sim.add_instrument(Opening())\n",
        "sim.add_instrument(Retaliating())\n",
        "sim.add_instrument(Forgiving())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KN6QvN-xAY-"
      },
      "source": [
        "Run the simulation.  If you get a warning about `Mean of empty slice`, that's ok."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ry8jTregxAY-"
      },
      "outputs": [],
      "source": [
        "#Runs simulations with a seed\n",
        "np.random.seed(17)\n",
        "sim.run(steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_7eMTaIxAY-"
      },
      "source": [
        "And let's look at some results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "H7LfNVafxAY_"
      },
      "outputs": [],
      "source": [
        "#Displays Mean Fitness\n",
        "plot_result(0, color='C0')\n",
        "plt.show('figs/chap12-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "hhvao69IxAY_"
      },
      "outputs": [],
      "source": [
        "#Shows Niceness (Average number of Cooperators across all agents)\n",
        "plot_result(1, color='C1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "RRDXT1BLxAY_"
      },
      "outputs": [],
      "source": [
        "#Shows Opening (Agents who started with cooperation)\n",
        "plot_result(2, color='C2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "oVyiJ13NxAZA"
      },
      "outputs": [],
      "source": [
        "#Shows Retaliation (Difference between agents who defect after defection and cooperate after defection)\n",
        "plot_result(3, color='C3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "UaKjRdfoxAZA"
      },
      "outputs": [],
      "source": [
        "#Shows average amount of agents who forgive a round or two after defection\n",
        "plot_result(4, color='C4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWR_Zw3rxAZA"
      },
      "source": [
        "The following cells explore the composition of the final population.  But because the distribution of agents varies so much over time, the details of a single timestep might not mean much.\n",
        "\n",
        "Here are the final genomes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rktzNpEYxAZA"
      },
      "outputs": [],
      "source": [
        "from pandas import Series\n",
        "\n",
        "responses = [''.join(agent.values) for agent in sim.agents]\n",
        "Series(responses).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "Kretz, T. (2010). A round-robin tournament of the iterated prisoner’s dilemma with complete memory-size-three strategies. Complex Systems, 19(4), 363–389. https://doi.org/10.25088/complexsystems.19.4.363\n",
        "\n",
        "Kuhn, S. (2019, April 2). Prisoner’s dilemma. Stanford Encyclopedia of Philosophy. https://plato.stanford.edu/entries/prisoner-dilemma/\n",
        "\n",
        "Picardo, E. (2024, August 28). The prisoner’s dilemma in business and the economy. Investopedia. https://www.investopedia.com/articles/investing/110513/utilizing-prisoners-dilemma-business-and-economy.asp\n",
        "\n",
        "Sussex Publishers. (n.d.). The prisoner’s dilemma in everyday life. Psychology Today. https://www.psychologytoday.com/us/blog/darwins-subterranean-world/202112/the-prisoners-dilemma-in-everyday-life\n",
        "\n",
        "Tobin, J. (n.d.). The prisoner’s dilemma. University of Michigan Heritage Project. https://heritage.umich.edu/stories/the-prisoners-dilemma/\n",
        "\n",
        "Vinney, C. (2024, August 29). What the prisoner’s dilemma teaches us about human behavior. Verywell Mind. https://www.verywellmind.com/prisoners-dilemma-8697893"
      ],
      "metadata": {
        "id": "Fy6S2BnvJiNp"
      }
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WR_tufC3xAYw",
        "JOVmpecYxAYx",
        "zsWGdiAHxAY0",
        "D2HcXMBexAY1"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}